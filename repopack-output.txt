This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2024-09-24T13:29:32.634Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
generating/
  generating_script_11062024_fractal_noise.py
testing/
  20240528-sample_report.py
  20240820-testing-vae-reconstruction.py
  make-control-report-3d.py
  make-report-3d-for-unconditional.py
  make-report-3d.py
  make-report.py
  make-validation.py
training/
  lightning_logs/
    version_0/
      hparams.yaml
    version_1/
      hparams.yaml
    version_2/
      hparams.yaml
    version_3/
      hparams.yaml
      metrics.csv
    version_4/
      hparams.yaml
  training-script-20240123-karras-edm.py
  training-script-20240124-ddpm-v2.py
  training-script-20240125-cascade.py
  training-script-20240125-ddpm-v1.py
  training-script-20240125-single.py
  training-script-20240222-karras-edm-all.py
  training-script-20240222-karras-mnist.py
  training-script-20240226-karras-edm-all-latent.py
  training-script-20240314-karras-edm-latent.py
  training-script-20240402-ocean-superres.py
  training-script-20240410-karras-edm-3d.py
  training-script-20240416-pore-superres.py
  training-script-20240418-ocean-poormangencast.py
  training-script-20240418-pore-superres.py
  training-script-20240430-autoencoder3d.py
  training-script-20240501-autoencoder2d.py
  training-script-20240502-4-autoencoder2d.py
  training-script-20240503-autoencoder2d.py
  training-script-20240506-karras-edm-punetb.py
  training-script-20240509-autoencoder2d.py
  training-script-20240513-autoencoder_ldm2d.py
  training-script-20240514-autoencoder_ldm3d.py
  training-script-20240514-karras-latent_diff1-punetb.py
  training-script-20240514-karras-latent_diff2-punetb.py
  training-script-20240520-autoencoder_ldm3d-a100.py
  training-script-20240520-karras-edm-3d-a100.py
  training-script-20240520-karras-ldm3d-a100.py
  training-script-20240521-karras-ldm3d-a100-norm.py
  training-script-20240521-poormangencast-cond.py
  training-script-20240527-karras-edm-punetb-a100.py
  training-script-20240606-porrgencast-multy-models.py
  training-script-20240610-karras-edm-punetc.py
  training-script-20240612-karras-edm-tpc.py
  training-script-20240617-karras-edm-tpc-3.py
  training-script-20240619-karras-edm.py
  training-script-20240620-karras-edm-g.py
  training-script-20240620-karras-edm-g2.py
  training-script-20240623-toy-chessboard.py
  training-script-20240624-edm-a100-tpc.py
  training-script-20240626-testing-scaling-laws.py
  training-script-20240628-porosity-control.py
  training-script-20240702-porosity-control-single-latent.py
  training-script-20240702-porosity-control-single.py
  training-script-20240703-nocond-latent.py
  training-script-20240703-nocond.py
  training-script-20240704-nocond-norm.py
  training-script-20240708-autoencoder_ldm3d-a100.py
  training-script-20240710-test-different-nets-attn.py
  training-script-20240710-test-different-nets.py
  training-script-20240711-karras-ldm3d-a100.py
  training-script-20240716-karras-ldm3d-256-a100.py
  training-script-20240717-test.py
  training-script-20240723-karras-ldm3d-norm-a100.py
  training-script-20240821-autoencoder_ldm3d-a100-refactor.py
  training-script-20240826-autoencoder_ldm3d-all-a100.py
  training-script-20240916-karras-nolatent-norm-a100.py
20231211-test-run.py
clean_ipynb.sh
Dockerfile-20231211-test-run
models_to_onnx.py
remote_tracking.sh

================================================================
Repository Files
================================================================

================
File: generating/generating_script_11062024_fractal_noise.py
================
import pathlib
import os

import numpy as np
import porespy
import pytictoc


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
SYNTHETICDATAPATH = MAINPATH/"saveddata"/"raw"/"synthetic"


def generate_fractal_image(size, porosity, frequency, octaves, gain):
    image = porespy.generators.fractal_noise([size, size, size],
                                             frequency=frequency,
                                             octaves=octaves,
                                             gain=gain)
    image = image > (1 - porosity)
    return image


def fractal_image_parameters_sampler():
    porosity = np.random.uniform(0.05, 0.5)
    frequency = np.random.exponential(0.05) + 0.01
    octaves = np.random.randint(1, 6)
    gain = np.random.uniform(0.1, 0.5)
    return porosity, frequency, octaves, gain


def two_point_correlation_estimate(image):
    size = image.shape[-1]
    data2d = porespy.metrics.two_point_correlation(image[:, :, size//2])
    distance = data2d.distance
    probscaled = data2d.probability_scaled
    return distance, probscaled


def generate_and_save_sample(index, run_id):
    porosity, frequency, octaves, gain = fractal_image_parameters_sampler()
    image = generate_fractal_image(128, porosity, frequency, octaves, gain)
    x, y = two_point_correlation_estimate(image)
    basename = (
        f"sample_{str(index).zfill(8)}"
        f"_p{porosity:.4f}"
        f"_f{frequency:.4f}"
        f"_o{octaves}_g{gain:.4f}"
        f".npz"
    )
    savedir = SYNTHETICDATAPATH/f"run_{str(run_id).zfill(3)}"
    try:
        os.makedirs(savedir)
    except FileExistsError:
        pass
    np.savez(savedir/basename, image=image, x=x, y=y)


if __name__ == "__main__":
    tictoc = pytictoc.TicToc()
    tictoc.tic()
    run_id = 2
    for i in range(int(5*1e5)):
        generate_and_save_sample(i, 2)
    tictoc.toc()

================
File: testing/20240528-sample_report.py
================
import pathlib
import argparse

import torch
import lightning
from lightning.pytorch.tuner.tuning import Tuner
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models
import poregen.metrics


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 savefolderstr: str,
                 validationstr: str,
                 nsamples = 1000,
                 shape = [1,128,128],
                 nsteps = 100,
                 ):
        self.savefolderstr = savefolderstr
        self.validationstr = validationstr
        self.nsamples = nsamples
        self.shape = shape
        self.nsteps = nsteps
        

def main(config, module):
    nsamples = config.nsamples
    shape = config.shape
    nsteps = config.nsteps
    savefolderstr = config.savefolderstr
    validationstr = config.validationstr
    
    # generate samples
    sample = module.sample(nsamples, shape, nsteps=nsteps, maximum_batch_size=500)
    torch.save(sample, MAINPATH/'output/bps-saved-samples'/savefolderstr)
    # sample = torch.load(MAINPATH/'output/bps-saved-samples/berea-punetb-mse-2000samples-100steps-edm')
    sample_bin = (sample > 0.5).int()
    sample_bin = sample_bin.float()
    validation = torch.load(MAINPATH/validationstr)

    # make report
    metric_creator = poregen.metrics.BinaryPorousImageMetrics()
    metric_creator.set_samples(sample_bin, validation)
    metric_creator.make_report(MAINPATH/'output/bps-reports', savefolderstr)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--checkpointpath', type=str, required=True)
    parser.add_argument('--validationstr', type=str,
                        default='output/bps-saved-samples/valid-set-2000samples-berea')
    parser.add_argument('--nsamples', type=int, default=2000)
    parser.add_argument('--shape', type=int, default=[1,128,128])
    parser.add_argument('--nsteps', type=int, default=100)
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    savefolderstr = args.savefolderstr
    validationstr = args.validationstr
    nsamples = args.nsamples
    shape = args.shape
    nsteps = args.nsteps

    # get model
    checkpoint_path = MAINPATH/args.checkpointpath
    model = poregen.models.PUNetBUncond(64, dropout=0.2)
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    module = poregen.models.KarrasModule.load_from_checkpoint(checkpoint_path,
                                                              model=model,
                                                              config=moduleconfig)
    module.eval();

    config = Config(savefolderstr,
                    validationstr,
                    nsamples,
                    shape,
                    nsteps)
    
    main(config, module)

================
File: testing/20240820-testing-vae-reconstruction.py
================
import pathlib

import torch
import lightning

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
RAWDATAPATH = MAINPATH/"saveddata"/"raw"


def main():
    voxel_size = 64
    number_of_samples_per_sandstone = 16

    checkpoint_path = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-08-21]-[dfn]-[64-noattn-vae-1-2-4-4-8-16]/sample-epoch=28-val/rec_loss=0.094070.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(kl_weight=1e-4)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        resolution=voxel_size,
        has_mid_attn=False,
        ch_mult=[1, 2, 4, 4, 8, 16])

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval();

    sandstones = ['Berea',
                  'BUG',
                  'Leopard',
                  'Bentheimer',
                  'Parker',
                  'BanderaBrown',
                  'Kirby',
                  'BanderaGray',
                  'CastleGate',
                  'BSG',
                  'BB']

    for sandstone in sandstones:
        datapath = RAWDATAPATH/f'eleven_sandstones/{sandstone}_2d25um_binary.raw'
        voxel = poregen.data.load_binary_from_eleven_sandstones(datapath)
        dataset = poregen.data.VoxelToSubvoxelDataset(
            voxel,
            voxel_size
        )


        print(f"Voxel size : {voxel_size}")
        with torch.inference_mode():
            vae_module.to("cpu")

            x_orig = torch.stack([
                dataset[i].to("cpu")
                for i in range(number_of_samples_per_sandstone)
            ], axis=0)
    
            x_encoded = vae_module.encode(x_orig)
            
            x_decoded = vae_module.decode(x_encoded)

            x_orig_bin = (x_orig > x_orig.mean(axis=(1, 2, 3, 4), keepdim=True))
            x_decoded_bin = (x_decoded > x_decoded.mean(axis=(1, 2, 3, 4), keepdim=True))

            score = (x_decoded_bin != x_orig_bin).float().mean(axis=(1, 2, 3, 4))

            print(sandstone)
            print(score.tolist())
            print('-'*10)


if __name__ == "__main__":
    main()

================
File: testing/make-control-report-3d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models
import poregen.metrics

import numpy as np


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 savefolderstr: str,
                 validationpath1: str,
                 validationpath2: str,
                 type: str = 'slices',
                 nslices: int = 10,
                 voxel_size: int = 64):
        self.savefolderstr = savefolderstr
        self.validationpath1 = validationpath1
        self.validationpath2 = validationpath2
        self.type = type
        self.nslices = nslices
        self.voxel_size = voxel_size


def main(config):
    type=config.type
    nslices = config.nslices
    voxsize = config.voxel_size
    validation = torch.load(MAINPATH/config.validationpath1)
    validation2 = torch.load(MAINPATH/config.validationpath2)

    if type=='slices':
        # to slices
        indexes = np.random.randint(low=0, high=voxsize, size=nslices)
        validation2d = []
        validation2_2d = []
        for i in range(nslices):
            validation2_2d.append(validation2[..., indexes[i]])
            validation2d.append(validation[..., indexes[i]])
        
        validation2d = torch.cat([torch.tensor(x) for x in validation2d], dim=0)
        validation2_2d = torch.cat([torch.tensor(x) for x in validation2_2d], dim=0)
        print('2D validation shapes:', validation2d.shape, validation2_2d.shape)

        # make report
        metric_creator = poregen.metrics.BinaryPorousImageMetrics()
        metric_creator.set_samples(validation2_2d, validation2d)
        savestr = 'output/bps-reports/' + savefolderstr
        metric_creator.make_report(MAINPATH, savestr, filter_noise=False)
    
    elif type=='voxels':
        print('3D validation shapes:', validation.shape, validation2.shape)
        # make report
        metric_creator = poregen.metrics.BinaryPorousImageMetrics()
        metric_creator.set_samples(validation2, validation)
        savestr = 'output/bps-reports/' + savefolderstr
        metric_creator.make_report(MAINPATH, savestr, filter_noise=False,
                                   dimension=3)
    else:
        raise ValueError('--type argument should be either slices or voxels')


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--validpath1', type=str, required=True)
    parser.add_argument('--validpath2', type=str, required=True)
    parser.add_argument('--type', type=str, default='slices')
    parser.add_argument('--voxelsize', type=int, default=64)
    args = parser.parse_args()
    savefolderstr = args.savefolderstr
    type = args.type
    voxel_size = args.voxelsize
    validationpath1 = args.validpath1
    validationpath2 = args.validpath2
    
    config = Config(savefolderstr,
                    validationpath1,
                    validationpath2,
                    type=type,
                    voxel_size=voxel_size)
    
    main(config)

================
File: testing/make-report-3d-for-unconditional.py
================
import pathlib
import argparse
from typing import Optional

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers
import numpy as np

import poregen.data
import poregen.models
import poregen.metrics

# Constants
CURRENT_PATH = pathlib.Path(__file__).parent.absolute()
MAIN_PATH = CURRENT_PATH.parent.parent
DATA_PATH = MAIN_PATH / "saveddata"
RAW_DATA_PATH = DATA_PATH / "raw"
MODELS_PATH = MAIN_PATH / "savedmodels" / "experimental"
OUTPUT_PATH = MAIN_PATH / "output"

class Config:
    def __init__(
        self,
        save_folder: str,
        model_path: str,
        integrator: str,
        sandstone: str,
        sample: bool = True,
        latent: bool = True,
        n_slices: int = 10,
        n_voxels: int = 100,
        n_steps: int = 50,
        p_split: float = 0.8,
        max_batch_size: int = 100,
        voxel_size: int = 64,
        filter_noise: bool = False
    ):
        self.save_folder = save_folder
        self.model_path = model_path
        self.integrator = integrator
        self.sandstone = sandstone
        self.sample = sample
        self.latent = latent
        self.n_slices = n_slices
        self.n_voxels = n_voxels
        self.n_steps = n_steps
        self.p_split = p_split
        self.max_batch_size = max_batch_size
        self.voxel_size = voxel_size
        self.filter_noise = filter_noise


def sample_data(module: poregen.models.KarrasModule, config: Config) -> torch.Tensor:
    if config.integrator == 'karras':
        module.config.noisescheduler.integrator = poregen.models.KarrasIntegrator()
        n_steps = 256
    elif config.integrator == 'ode':
        n_steps = config.n_steps
    elif config.integrator == 'sde':
        module.config.noisescheduler.integrator = poregen.models.EulerMaruyamaIntegrator()
        n_steps = 256
    else:
        raise ValueError(f"Invalid integrator: {config.integrator}. Choose 'ode', 'sde', or 'karras'.")

    sample = module.sample(
        config.n_voxels,
        [1, config.voxel_size, config.voxel_size, config.voxel_size],
        nsteps=n_steps,
        maximum_batch_size=config.max_batch_size
    )

    if not config.latent:
        sample = sample + 0.5

    return sample


def load_or_generate_sample(module: poregen.models.KarrasModule, config: Config) -> torch.Tensor:
    if config.sample:
        print('Sampling!')
        sample = sample_data(module, config)
        torch.save(sample, OUTPUT_PATH / 'bps-saved-samples' / config.save_folder)
    else:
        sample = torch.load(OUTPUT_PATH / 'bps-saved-samples' / config.save_folder)
    
    return sample


def generate_validation(config: Config) -> torch.Tensor:
    sandstone_path = RAW_DATA_PATH / 'eleven_sandstones' / f'{config.sandstone}_2d25um_binary.raw'
    dataset = poregen.data.VoxelToSubvoxelDataset(
        voxel=poregen.data.load_binary_from_eleven_sandstones(sandstone_path),
        subslice=config.voxel_size
    )
    voxels = torch.stack([dataset[i] for i in range(config.n_voxels)], axis=0)
    voxels_mean = voxels.mean(dim=tuple(range(1, voxels.ndim)), keepdims=True)
    voxels_bin = (voxels > voxels_mean).float()
    return voxels_bin


def create_metrics_report(sample: torch.Tensor, validation: torch.Tensor, config: Config):
    sample_mean = sample.mean(dim=tuple(range(1, sample.ndim)), keepdims=True)
    sample_bin = (sample > sample_mean).float()
    metric_creator = poregen.metrics.BinaryPorousImageMetrics()
    metric_creator.set_samples(sample_bin, validation)
    save_str = f'output/bps-reports/{config.save_folder}'
    metric_creator.make_report(MAIN_PATH, save_str, filter_noise=config.filter_noise, dimension=3)


def load_model(config: Config) -> poregen.models.KarrasModule:
    module_config = poregen.models.KarrasModuleConfig.from_edm()

    channels = 4 if config.latent else 1
    
    net_config = poregen.models.PUNetGConfig(
        input_channels=channels,
        output_channels=channels,
        dimension=3,
        number_resnet_attn_block=0,
        number_resnet_before_attn_block=3,
        number_resnet_after_attn_block=3
    )
    model = poregen.models.PUNetG(net_config)

    vae_module = None
    if config.latent:
        vae_checkpoint = MODELS_PATH / '[pore]-[2024-08-13]-[bps]-[64-noatt-autoencoder-1e-4-banderabrown]/sample-epoch=104-val/rec_loss=0.005341.ckpt'
        loss_config = poregen.models.nets.autoencoderldm3d.lossconfig(kl_weight=1e-4)
        dd_config = poregen.models.nets.autoencoderldm3d.ddconfig(resolution=config.voxel_size, has_mid_attn=False)
        vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
            vae_checkpoint, ddconfig=dd_config, lossconfig=loss_config
        )
        vae_module.eval()

    diff_checkpoint = MAIN_PATH / config.model_path
    module = poregen.models.KarrasModule.load_from_checkpoint(
        diff_checkpoint,
        model=model,
        config=module_config,
        autoencoder=vae_module
    )
    module.norm = 20  # For normalized latent space

    return module


def main(config: Config):
    module = load_model(config)
    validation = generate_validation(config)
    sample = load_or_generate_sample(module, config)
    create_metrics_report(sample, validation, config)


def parse_arguments() -> Config:
    parser = argparse.ArgumentParser(description="poregen Script")
    parser.add_argument('--save-folder', type=str, required=True, help="Folder to save results")
    parser.add_argument('--model-path', type=str, required=True, help="Relative path of the model to be loaded")
    parser.add_argument('--integrator', type=str, default='ode', choices=['ode', 'sde', 'karras'], help="Integrator type")
    parser.add_argument('--sandstone', type=str, default='Berea', help="Sandstone type")
    parser.add_argument('--latent', type=str, default='yes', choices=['yes', 'no'], help="Use latent space")
    parser.add_argument('--sample', type=str, default='yes', choices=['yes', 'no'], help="Sample data")
    parser.add_argument('--n-voxels', type=int, default=500, help="Number of voxels")
    parser.add_argument('--filter-noise', type=str, default='no', choices=['yes', 'no'], help="Filter noise")
    parser.add_argument('--voxel-size', type=int, default=64, help="Voxel size")

    args = parser.parse_args()
    
    return Config(
        save_folder=args.save_folder,
        model_path=args.model_path,
        integrator=args.integrator,
        sandstone=args.sandstone,
        sample=args.sample == 'yes',
        latent=args.latent == 'yes',
        n_voxels=args.n_voxels,
        filter_noise=args.filter_noise == 'yes',
        voxel_size=args.voxel_size
    )

if __name__ == "__main__":
    config = parse_arguments()
    main(config)

================
File: testing/make-report-3d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models
import poregen.metrics

import numpy as np


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 savefolderstr: str,
                 integrator: str,
                 validationpath: str,
                 sample: bool = True,
                 datastr: str = None,
                 latent: bool = True,
                 type: str = 'slices',
                 nslices: int = 10,
                 nvoxels: int = 100,
                 nsteps: int = 50,
                 psplit: float = 0.8,
                 max_batch_size: int = 100,
                 voxel_size: int = 64,
                 filternoise: bool = False):
        self.savefolderstr = savefolderstr
        self.integrator = integrator
        self.validationpath = validationpath
        self.type = type
        self.sample = sample
        self.datastr = datastr
        self.latent = latent
        self.nslices = nslices
        self.nvoxels = nvoxels
        self.nsteps = nsteps
        self.psplit = psplit
        self.max_batch_size = max_batch_size
        self.voxel_size = voxel_size
        self.filternoise = filternoise


def main(config, module):
    nslices = config.nslices
    nvoxel_samples = config.nvoxels
    voxsize = config.voxel_size
    if config.sample:
        print('Sampling!')
        if config.integrator=='karras':
            module.config.noisescheduler.integrator = poregen.models.KarrasIntegrator()
            sample = module.sample(nvoxel_samples,
                                [1, voxsize, voxsize, voxsize],
                                nsteps=256,
                                maximum_batch_size=config.max_batch_size)
        elif config.integrator=='ode':
            sample = module.sample(nvoxel_samples,
                                [1, voxsize, voxsize, voxsize],
                                nsteps=config.nsteps,
                                maximum_batch_size=config.max_batch_size)
        elif config.integrator=='sde':
            module.config.noisescheduler.integrator = poregen.models.EulerMaruyamaIntegrator()
            sample = module.sample(nvoxel_samples,
                                [1, voxsize, voxsize, voxsize],
                                nsteps=256,
                                maximum_batch_size=config.max_batch_size)
        else:
            raise NameError('argument --integrator should be either ode, sde or karras')
        if not config.latent:
            sample = sample + 0.5
        
        torch.save(sample, MAINPATH/'output/bps-saved-samples'/config.savefolderstr)
    else:
        datastr = config.datastr
        if datastr is None:
            raise ValueError('--datastr argument should be passed if --sample=no')
        sample = torch.load(MAINPATH/datastr)
    
    sample_bin = (sample > 0.5).int()
    sample_bin = sample_bin.float()
    validation = torch.load(MAINPATH/config.validationpath)

    if config.type=='slices':
        # to slices
        indexes = np.random.randint(low=0, high=voxsize, size=nslices)
        validation2d = []
        samples2d = []
        for i in range(nslices):
            samples2d.append(sample_bin[..., indexes[i]])
            validation2d.append(validation[..., indexes[i]])
        
        validation2d = torch.cat([torch.tensor(x) for x in validation2d], dim=0)
        samples2d = torch.cat([torch.tensor(x) for x in samples2d], dim=0)

        # make report
        metric_creator = poregen.metrics.BinaryPorousImageMetrics()
        metric_creator.set_samples(samples2d, validation2d)
        savestr = 'output/bps-reports/' + savefolderstr
        metric_creator.make_report(MAINPATH, savestr, filter_noise=config.filternoise)
    
    elif config.type=='voxels':
        # make report
        metric_creator = poregen.metrics.BinaryPorousImageMetrics()
        metric_creator.set_samples(sample_bin, validation)
        savestr = 'output/bps-reports/' + savefolderstr
        metric_creator.make_report(MAINPATH, savestr, filter_noise=config.filternoise,
                                   dimension=3)
    else:
        raise ValueError('--type argument should be either slices or voxels')


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--model', type=str, default='punetg')
    parser.add_argument('--integrator', type=str, required=True)
    parser.add_argument('--sandstone', type=str, default='berea')
    parser.add_argument('--latent', type=str, default='yes')
    parser.add_argument('--sample', type=str, default='yes')
    parser.add_argument('--diffcheckpoint', type=str, default=None)
    parser.add_argument('--modelchannels', type=int, default=64)
    parser.add_argument('--datastr', type=str, default=None)
    parser.add_argument('--type', type=str, default='slices')
    parser.add_argument('--nvoxels', type=int, default=500)
    parser.add_argument('--filternoise', type=str, default='no')
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--voxelsize', type=int, default=64)
    
    args = parser.parse_args()
    sandstone = args.sandstone
    if sandstone=='berea':
        validationpath = 'output/bps-saved-samples/validation3d-500samples-berea64'
        vae_checkpoint = (
             MAINPATH/'savedmodels/production/[pore]-[2024-07-09]-[bps]-[64berea-noatt-autoencoder-1e-4]/sample-epoch=95-val/rec_loss=0.003954.ckpt')
    elif sandstone=='banderabrown':
        validationpath = 'output/bps-saved-samples/validation3d-500samples-banderabrown64'
        vae_checkpoint = (
             MAINPATH/'savedmodels/production/[pore]-[2024-08-13]-[bps]-[64banderabrown-noatt-autoencoder-1e-4]/sample-epoch=104-val/rec_loss=0.005341.ckpt')
    elif sandstone=='estaillades':
        validationpath = 'output/bps-saved-samples/validation3d-500samples-estaillades64'
        # vae_checkpoint = (
        #      MAINPATH/'savedmodels/experimental/[pore]-[2024-09-10]-[bps]-[64estaillades-noatt-autoencoder-1e-4]/sample-epoch=31-val/rec_loss=0.002858.ckpt')
        vae_checkpoint = (
             MAINPATH/'savedmodels/production/[pore]-[2024-07-09]-[bps]-[64berea-noatt-autoencoder-1e-4]/sample-epoch=95-val/rec_loss=0.003954.ckpt')
    else:
        raise ValueError('-sandstone argument should be either berea, banderabrown or estaillades')
    
    savefolderstr = args.savefolderstr
    net = args.model
    integrator = args.integrator
    voxel_size = args.voxelsize
    type = args.type
    datastr = args.datastr
    diffcheckpoint = args.diffcheckpoint
    modelchannels = args.modelchannels

    if args.sample=='yes':
        sample=True
    elif args.sample=='no':
        sample=False                 # argparse seems not to work with bool
    else:
        raise ValueError('--sample argument should be either yes or no')
    
    if args.latent=='yes':
        latent=True
    elif args.latent=='no':
        latent=False                 # argparse seems not to work with bool
    else:
        raise ValueError('--latent argument should be either yes or no')
    
    if args.filternoise=='yes':
        filternoise=True
    elif args.filternoise=='no':
        filternoise=False
    else:
        raise ValueError('--filternoise argument should be either yes or no')
    
    nvoxels = args.nvoxels
    # if nvoxels==100:
    #     validationpath = 'output/bps-saved-samples/validation3d-100samples-berea64'
    # elif nvoxels==500:
    #     validationpath = 'output/bps-saved-samples/validation3d-500samples-berea64'
    # else:
    #     raise ValueError('--nvoxels argument should be either 100 or 500')
    
    if args.framework == 'edm':
            moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    if latent:
        channels = 4
        max_batch_size = 100
    else:
         channels = 1
         max_batch_size = 50
        
    if voxel_size==32:
        validationpath = 'output/bps-saved-samples/validation3d-1000samples-berea32'
        print('Validation: 1000 volumes of Berea 32!')

    if voxel_size==128:
        validationpath = 'output/bps-saved-samples/validation3d-500samples-berea128'
        max_batch_size = 10
        if sandstone=='banderabrown':
            validationpath = 'output/bps-saved-samples/validation3d-500samples-banderabrown128'

    if voxel_size==256:
        validationpath = 'output/bps-saved-samples/validation3d-100samples-berea256'
        max_batch_size = 1
        if sandstone=='banderabrown':
            validationpath = 'output/bps-saved-samples/validation3d-100samples-banderabrown256'

    if sample:
        if diffcheckpoint is None:
            raise ValueError('--diffcheckpoint argument should be passed if --sample=yes')
        diffcheckpoint = (MAINPATH/diffcheckpoint)
        if net=='punetg':
            netconfig = poregen.models.PUNetGConfig(input_channels=channels,
                                                output_channels=channels,
                                                model_channels=modelchannels,
                                                dimension=3,
                                                number_resnet_attn_block=0,
                                                number_resnet_before_attn_block=3,
                                                number_resnet_after_attn_block=3
                                                )
            model = poregen.models.PUNetG(netconfig)
        elif net=='edm2':
            model = poregen.models.UNet3D(img_resolution=voxel_size,
                                        img_channels=channels,
                                        label_dim=0,
                                        model_channels=32,
                                        dropout=0.1)
        else:
            raise NameError('argument --model should be either edm2 or punetg')
        
        if latent:
            lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(kl_weight=1e-4)
            ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
                resolution=voxel_size,
                has_mid_attn=False)
            vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
                vae_checkpoint, ddconfig=ddconfig, lossconfig=lossconfig
                )
            vae_module.eval()

            module = poregen.models.KarrasModule.load_from_checkpoint(
                diffcheckpoint,
                model=model,
                config=moduleconfig,
                autoencoder=vae_module)
            # for normalized latent space
            module.norm = 20
        else:
            module = poregen.models.KarrasModule.load_from_checkpoint(
                diffcheckpoint,
                model=model,
                config=moduleconfig)
    else:
        module = None
    

    config = Config(savefolderstr,
                    integrator,
                    validationpath,
                    sample=sample,
                    datastr=datastr,
                    latent=latent,
                    type=type,
                    voxel_size=voxel_size,
                    filternoise=filternoise,
                    max_batch_size=max_batch_size,
                    nvoxels=nvoxels)
    
    main(config, module)

================
File: testing/make-report.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 validationpath: str,
                 nsamples: int = 1000,
                 shape: int = [1, 192, 192],
                 nsteps: int = 50,
                 psplit: float = 0.8,
                 max_batch_size: int = 200,
                 voxel_size: int = 64):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.validationpath = validationpath
        self.nsamples = nsamples
        self.shape = shape
        self.nsteps = nsteps
        self.psplit = psplit
        self.max_batch_size = max_batch_size
        self.voxel_size = voxel_size


def main(config, module):

    sample = module.sample(config.nsamples,
                           config.shape,
                           nsteps=config.nsteps,
                           maximum_batch_size=config.max_batch_size)

    torch.save(sample, module.savefolderstr)
    validation = torch.load(MAINPATH/module.validationpath)

    sample_bin = (sample > 0.5).int()
    sample_bin = sample_bin.float()

    metric_creator = poregen.metrics.BinaryPorousImageMetrics()
    metric_creator.set_samples(sample_bin, validation)
    metric_creator.make_report(MAINPATH, 'output/bps-reports/'/savefolderstr)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--validationpath', type=str, 
                        default='output/bps-saved-samples/valid-set-2000samples-berea')
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--voxelsize', type=int, default=64)
    # savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    validationpath = args.validationpath
    voxel_size = args.voxelsize

    model = poregen.models.PUNetBUncond(64, dropout=0.2)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    checkpoint_path=(MAINPATH/'savedmodels/experimental/[pore]-[2024-06-06]-[bps]-[ldmvae3d-64]/sample-epoch=130-val/rec_loss=0.008684.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(
        kl_weight=1.0)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        ch=32,
        ch_mult=(1,2,2),
        resolution=voxel_size,
        dropout=0.1)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    # checkpoint = (MAINPATH/'savedmodels/experimental/[pore]-[2024-05-20]-[bps]-[berealdm3d]/sample-epoch=29-valid_loss=7.609305.ckpt')

    # module = poregen.models.KarrasModule.load_from_checkpoint(
    #     checkpoint,
    #     model=model,
    #     config=moduleconfig,
    #     autoencoder=vae_module)

    module = poregen.models.KarrasModule(
        model=model,
        config=moduleconfig,
        autoencoder=vae_module)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    voxel_size=voxel_size,
                    learning_rate=1e-3,
                    batch_size=100,
                    num_epochs=200)
    
    main(config, module)

================
File: testing/make-validation.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models
import poregen.metrics

import numpy as np


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


def main(volume_size, nsamples, dataname, savestr, psplit):

    dataname_path = RAWDATAPATH/dataname
    voxel = poregen.data.load_binary_from_eleven_sandstones(dataname_path)
    valid_voxel = voxel[int(1000 * psplit):, :, :]
    transform = poregen.data.get_standard_binary_transforms()
    dataset = poregen.data.VoxelToSubvoxelDataset(valid_voxel, transform=transform, subslice=volume_size)

    validation = dataset[0,:,:].unsqueeze(0)
    for i in range(nsamples-1):
        validation = torch.cat((validation, dataset[i+1,:,:].unsqueeze(0)))
    print(validation.shape)

    # save validation tensor
    savepath = MAINPATH/'output/bps-saved-samples'/savestr
    torch.save(validation, savepath)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--savestr', type=str, required=True)
    parser.add_argument('--sandstone', type=str, default='berea')
    parser.add_argument('--nvoxels', type=int, default=500)
    parser.add_argument('--voxelsize', type=int, default=64)

    args = parser.parse_args()
    sandstone = args.sandstone
    if sandstone=='berea':
        dataname = "eleven_sandstones/Berea_2d25um_binary.raw"
    elif sandstone=='banderabrown':
        dataname = "eleven_sandstones/BanderaBrown_2d25um_binary.raw"
    elif sandstone=='estaillades':
        dataname = "imperial_college/Estaillades_1000c_3p31136um.raw"
    else:
        raise ValueError('-sandstone argument should be either berea, banderabrown or estaillades')
    
    savestr = args.savestr
    volume_size = args.voxelsize
    nvoxels = args.nvoxels

    if volume_size==256:
        psplit = 0.7
    else:
        psplit = 0.8
    
    main(volume_size=volume_size,
         nsamples=nvoxels,
         dataname=dataname,
         savestr=savestr,
         psplit=psplit)

================
File: training/lightning_logs/version_0/hparams.yaml
================
{}

================
File: training/lightning_logs/version_1/hparams.yaml
================
{}

================
File: training/lightning_logs/version_2/hparams.yaml
================
{}

================
File: training/lightning_logs/version_3/hparams.yaml
================
{}

================
File: training/lightning_logs/version_3/metrics.csv
================
train_loss,step,epoch,valid_loss
0.36859041452407837,49,0,
0.32280218601226807,99,0,
0.2966879904270172,149,0,
0.17676949501037598,199,0,
0.22285287082195282,249,0,
0.16913123428821564,299,0,
0.16140349209308624,349,0,
0.1520998328924179,399,0,
0.17594507336616516,449,0,
0.15362034738063812,499,0,
,539,0,0.13566814363002777
0.14297260344028473,549,1,
0.12539075314998627,599,1,
0.1254109889268875,649,1,
0.14296847581863403,699,1,
0.1105726882815361,749,1,
0.10473106056451797,799,1,
0.11585169285535812,849,1,
0.11490423232316971,899,1,
0.12032678723335266,949,1,
0.11730960011482239,999,1,
0.09123128652572632,1049,1,
,1079,1,0.09219304472208023
0.11512662470340729,1099,2,
0.10600914061069489,1149,2,
0.12941181659698486,1199,2,
0.1318613737821579,1249,2,
0.095881886780262,1299,2,
0.09995416551828384,1349,2,
0.10098538547754288,1399,2,
0.0856277123093605,1449,2,
0.09831980615854263,1499,2,
0.09092777222394943,1549,2,
0.08094547688961029,1599,2,
,1619,2,0.0759616270661354
0.07435573637485504,1649,3,
0.07023978233337402,1699,3,
0.10687658935785294,1749,3,
0.08701266348361969,1799,3,
0.0866272822022438,1849,3,
0.08616066724061966,1899,3,
0.0822291374206543,1949,3,
0.11364664137363434,1999,3,
0.09629152715206146,2049,3,
0.08704692125320435,2099,3,
0.07776282727718353,2149,3,
,2159,3,0.06618660688400269
0.08070053160190582,2199,4,
0.0741506963968277,2249,4,
0.09104023873806,2299,4,
0.08325330168008804,2349,4,
0.08479473739862442,2399,4,
0.07035956531763077,2449,4,
0.07838693261146545,2499,4,
0.08580054342746735,2549,4,
0.06247708573937416,2599,4,
0.06887708604335785,2649,4,
0.07824928313493729,2699,4,
,2699,4,0.05927719548344612
0.07715237140655518,2749,5,
0.08627516776323318,2799,5,
0.07392481714487076,2849,5,
0.06461895257234573,2899,5,
0.058807823807001114,2949,5,
0.057986896485090256,2999,5,
0.05745694413781166,3049,5,
0.057968009263277054,3099,5,
0.06975918263196945,3149,5,
0.07756446301937103,3199,5,
,3239,5,0.05470282584428787
0.050210822373628616,3249,6,
0.05700245872139931,3299,6,
0.08014585822820663,3349,6,
0.06153690069913864,3399,6,
0.05823082476854324,3449,6,
0.05889115110039711,3499,6,
0.050096914172172546,3549,6,
0.055815260857343674,3599,6,
0.05547288432717323,3649,6,
0.05635737627744675,3699,6,
0.060702402144670486,3749,6,
,3779,6,0.049338940531015396
0.06896284967660904,3799,7,
0.05930492654442787,3849,7,
0.06205284595489502,3899,7,
0.05445929244160652,3949,7,
0.05446288734674454,3999,7,
0.0581468865275383,4049,7,
0.0523650236427784,4099,7,
0.06420186161994934,4149,7,
0.07363545894622803,4199,7,
0.07532498240470886,4249,7,
0.06279972195625305,4299,7,
,4319,7,0.04604082927107811
0.046495579183101654,4349,8,
0.055235203355550766,4399,8,
0.054165832698345184,4449,8,
0.04753967002034187,4499,8,
0.0449262298643589,4549,8,
0.05288403481245041,4599,8,
0.04569574072957039,4649,8,
0.039055753499269485,4699,8,
0.04245467483997345,4749,8,
0.05336664989590645,4799,8,
0.0624481700360775,4849,8,
,4859,8,0.04409893602132797
0.0675511360168457,4899,9,
0.046829644590616226,4949,9,
0.04701415076851845,4999,9,
0.05600876361131668,5049,9,
0.05818457901477814,5099,9,
0.04298502206802368,5149,9,
0.03675675764679909,5199,9,
0.04513179510831833,5249,9,
0.035489968955516815,5299,9,
0.03900180384516716,5349,9,
0.05484069138765335,5399,9,
,5399,9,0.040901586413383484
0.035944681614637375,5449,10,
0.054169636219739914,5499,10,
0.04499742388725281,5549,10,
0.059048157185316086,5599,10,
0.03642025962471962,5649,10,
0.057049501687288284,5699,10,
0.052207548171281815,5749,10,
0.03389555960893631,5799,10,
0.05302765220403671,5849,10,
0.039069633930921555,5899,10,
,5939,10,0.039095256477594376
0.03786983713507652,5949,11,
0.04401306435465813,5999,11,
0.05399519205093384,6049,11,
0.04977663233876228,6099,11,
0.054288845509290695,6149,11,
0.05223863199353218,6199,11,
0.04737470671534538,6249,11,
0.07556131482124329,6299,11,
0.03975684195756912,6349,11,
0.051895514130592346,6399,11,
0.05236905440688133,6449,11,
,6479,11,0.037541329860687256
0.04126227647066116,6499,12,
0.04185767471790314,6549,12,
0.04104553908109665,6599,12,
0.0403459295630455,6649,12,
0.03131561726331711,6699,12,
0.0435071736574173,6749,12,
0.050138235092163086,6799,12,
0.06312773376703262,6849,12,
0.05179138481616974,6899,12,
0.06027115136384964,6949,12,
0.03069223277270794,6999,12,
,7019,12,0.035614896565675735
0.04296175017952919,7049,13,
0.050280775874853134,7099,13,
0.04617860168218613,7149,13,
0.041248828172683716,7199,13,
0.04259930178523064,7249,13,
0.030759181827306747,7299,13,
0.04432661831378937,7349,13,
0.041591159999370575,7399,13,
0.036223139613866806,7449,13,
0.02405015006661415,7499,13,
0.03714587911963463,7549,13,
,7559,13,0.03537231683731079
0.04157334938645363,7599,14,
0.030091816559433937,7649,14,
0.025302231311798096,7699,14,
0.04236072674393654,7749,14,
0.0341394767165184,7799,14,
0.05205322057008743,7849,14,
0.040981486439704895,7899,14,
0.04323707893490791,7949,14,
0.04764239862561226,7999,14,
0.0360923670232296,8049,14,
0.027210397645831108,8099,14,
,8099,14,0.03462809696793556
0.027323907241225243,8149,15,
0.034655530005693436,8199,15,
0.03951183333992958,8249,15,
0.033178165555000305,8299,15,
0.04811445251107216,8349,15,
0.03571605682373047,8399,15,
0.044546984136104584,8449,15,
0.03943726792931557,8499,15,
0.03732208535075188,8549,15,
0.026855355128645897,8599,15,
,8639,15,0.03365210071206093
0.03346835449337959,8649,16,
0.024803949519991875,8699,16,
0.03316187113523483,8749,16,
0.03300989419221878,8799,16,
0.03177855536341667,8849,16,
0.04051573947072029,8899,16,
0.03178872540593147,8949,16,
0.026835598051548004,8999,16,
0.03117125667631626,9049,16,
0.04572039097547531,9099,16,
0.035622213035821915,9149,16,
,9179,16,0.03345351293683052
0.03960862383246422,9199,17,
0.031584128737449646,9249,17,
0.0298831257969141,9299,17,
0.052260398864746094,9349,17,
0.03861707076430321,9399,17,
0.052359528839588165,9449,17,
0.03642166778445244,9499,17,
0.023885734379291534,9549,17,
0.03640361875295639,9599,17,
0.048181548714637756,9649,17,
0.06495194882154465,9699,17,
,9719,17,0.032477814704179764
0.03997652605175972,9749,18,
0.04545476660132408,9799,18,
0.03683493658900261,9849,18,
0.042060572654008865,9899,18,
0.03286638483405113,9949,18,
0.03543820232152939,9999,18,
0.044281598180532455,10049,18,
0.05024581775069237,10099,18,
0.027535147964954376,10149,18,
0.04613487049937248,10199,18,
0.03407590836286545,10249,18,
,10259,18,0.03272604942321777
0.03389986231923103,10299,19,
0.030071565881371498,10349,19,
0.0337936207652092,10399,19,
0.04240088909864426,10449,19,
0.05392645671963692,10499,19,
0.040355756878852844,10549,19,
0.031995583325624466,10599,19,
0.035391099750995636,10649,19,
0.03843428194522858,10699,19,
0.03887882083654404,10749,19,
0.04281115531921387,10799,19,
,10799,19,0.031856875866651535
0.021686958149075508,10849,20,
0.03460683301091194,10899,20,
0.03522198274731636,10949,20,
0.0316067598760128,10999,20,
0.03170352801680565,11049,20,
0.03477070853114128,11099,20,
0.03195127472281456,11149,20,
0.023090654984116554,11199,20,
0.054827142506837845,11249,20,
0.037025801837444305,11299,20,
,11339,20,0.031423334032297134
0.025132209062576294,11349,21,
0.058688171207904816,11399,21,
0.04324342682957649,11449,21,
0.0351109504699707,11499,21,
0.04740985855460167,11549,21,
0.05254480615258217,11599,21,
0.026684744283556938,11649,21,
0.02248571813106537,11699,21,
0.05285568907856941,11749,21,
0.03219396620988846,11799,21,
0.0257406085729599,11849,21,
,11879,21,0.031248046085238457
0.04884165897965431,11899,22,
0.05045141652226448,11949,22,
0.025384508073329926,11999,22,
0.02357112243771553,12049,22,
0.021366683766245842,12099,22,
0.01646287366747856,12149,22,
0.030919555574655533,12199,22,
0.02655831351876259,12249,22,
0.045597560703754425,12299,22,
0.031144997105002403,12349,22,
0.020560123026371002,12399,22,
,12419,22,0.030637452378869057
0.035259444266557693,12449,23,
0.03675165772438049,12499,23,
0.03152624890208244,12549,23,
0.03489748761057854,12599,23,
0.037480924278497696,12649,23,
0.0274082962423563,12699,23,
0.02587515115737915,12749,23,
0.039787884801626205,12799,23,
0.025736987590789795,12849,23,
0.031130215153098106,12899,23,
0.026407208293676376,12949,23,
,12959,23,0.030242793262004852
0.03959934785962105,12999,24,
0.03894135355949402,13049,24,
0.025845594704151154,13099,24,
0.02597643807530403,13149,24,
0.026254819706082344,13199,24,
0.042200107127428055,13249,24,
0.05488256365060806,13299,24,
0.037137921899557114,13349,24,
0.025133082643151283,13399,24,
0.05038205161690712,13449,24,
0.04940395429730415,13499,24,
,13499,24,0.030467592179775238
0.03574560210108757,13549,25,
0.02547415718436241,13599,25,
0.03516871854662895,13649,25,
0.029627740383148193,13699,25,
0.031371548771858215,13749,25,
0.02631019800901413,13799,25,
0.0285087488591671,13849,25,
0.02847052924335003,13899,25,
0.028222236782312393,13949,25,
0.021056614816188812,13999,25,
,14039,25,0.030325787141919136
0.030400577932596207,14049,26,
0.0501069538295269,14099,26,
0.03794392943382263,14149,26,
0.03799634054303169,14199,26,
0.03587882220745087,14249,26,
0.03463902696967125,14299,26,
0.04747366905212402,14349,26,
0.021501369774341583,14399,26,
0.06516265869140625,14449,26,
0.024137938395142555,14499,26,
0.04084138199687004,14549,26,
,14579,26,0.0303500983864069
0.033592525869607925,14599,27,
0.05101966857910156,14649,27,
0.052695054560899734,14699,27,
0.027072615921497345,14749,27,
0.024370048195123672,14799,27,
0.037586577236652374,14849,27,
0.026278043165802956,14899,27,
0.03068324364721775,14949,27,
0.02154696360230446,14999,27,
0.038658466190099716,15049,27,
0.04898618534207344,15099,27,
,15119,27,0.029904689639806747
0.04305390641093254,15149,28,
0.05022616311907768,15199,28,
0.04852207005023956,15249,28,
0.05682700127363205,15299,28,
0.029039660468697548,15349,28,
0.03515065461397171,15399,28,
0.035410214215517044,15449,28,
0.03387658670544624,15499,28,
0.025962738320231438,15549,28,
0.019530918449163437,15599,28,
0.0535288006067276,15649,28,
,15659,28,0.029532095417380333
0.019322799518704414,15699,29,
0.031094755977392197,15749,29,
0.043169401586055756,15799,29,
0.027008656412363052,15849,29,
0.03449307009577751,15899,29,
0.031587883830070496,15949,29,
0.02662431262433529,15999,29,
0.04974927380681038,16049,29,
0.04200655594468117,16099,29,
0.038487739861011505,16149,29,
0.03333311155438423,16199,29,
,16199,29,0.02909579686820507
0.022217219695448875,16249,30,
0.027394043281674385,16299,30,
0.020838787779211998,16349,30,
0.029296137392520905,16399,30,
0.01874619349837303,16449,30,
0.041438356041908264,16499,30,
0.04009388014674187,16549,30,
0.029887981712818146,16599,30,
0.04483611136674881,16649,30,
0.02559829317033291,16699,30,
,16739,30,0.02937839739024639
0.030041376128792763,16749,31,
0.0614929124712944,16799,31,
0.03224598616361618,16849,31,
0.029504669830203056,16899,31,
0.031169630587100983,16949,31,
0.05184665694832802,16999,31,
0.05283789336681366,17049,31,
0.03025726228952408,17099,31,
0.03450172394514084,17149,31,
0.03241145983338356,17199,31,
0.01941158063709736,17249,31,
,17279,31,0.029911676421761513
0.04016948491334915,17299,32,
0.03630621358752251,17349,32,
0.04275258257985115,17399,32,
0.03406628593802452,17449,32,
0.0503968670964241,17499,32,
0.037810638546943665,17549,32,
0.036956872791051865,17599,32,
0.021332425996661186,17649,32,
0.04600319638848305,17699,32,
0.02198529615998268,17749,32,
0.03989870101213455,17799,32,
,17819,32,0.029095178470015526
0.05649656802415848,17849,33,
0.04855071008205414,17899,33,
0.018009210005402565,17949,33,
0.022136205807328224,17999,33,
0.0308762788772583,18049,33,
0.022490303963422775,18099,33,
0.03502809256315231,18149,33,
0.03233690559864044,18199,33,
0.023367639631032944,18249,33,
0.02582716755568981,18299,33,
0.03680568188428879,18349,33,
,18359,33,0.029231203719973564
0.014911575242877007,18399,34,
0.04092362895607948,18449,34,
0.020530754700303078,18499,34,
0.02831108309328556,18549,34,
0.0259518064558506,18599,34,
0.08053459972143173,18649,34,
0.021431148052215576,18699,34,
0.03740508854389191,18749,34,
0.0371735505759716,18799,34,
0.031707219779491425,18849,34,
0.0397067591547966,18899,34,
,18899,34,0.028824448585510254
0.02668645605444908,18949,35,
0.025798413902521133,18999,35,
0.041054487228393555,19049,35,
0.02815367467701435,19099,35,
0.04317888990044594,19149,35,
0.03434179723262787,19199,35,
0.04641879349946976,19249,35,
0.03309256583452225,19299,35,
0.024722669273614883,19349,35,
0.029749764129519463,19399,35,
,19439,35,0.029194053262472153
0.018501129001379013,19449,36,
0.024936825037002563,19499,36,
0.022280659526586533,19549,36,
0.017750335857272148,19599,36,
0.0363544337451458,19649,36,
0.025942817330360413,19699,36,
0.04305214434862137,19749,36,
0.028238236904144287,19799,36,
0.03984854742884636,19849,36,
0.019508028402924538,19899,36,
0.02953070029616356,19949,36,
,19979,36,0.029007261618971825
0.024890339002013206,19999,37,
0.03344627097249031,20049,37,
0.04094496741890907,20099,37,
0.036749787628650665,20149,37,
0.019909901544451714,20199,37,
0.019679341465234756,20249,37,
0.04480414092540741,20299,37,
0.04580983892083168,20349,37,
0.03485575690865517,20399,37,
0.01716657541692257,20449,37,
0.01738421805202961,20499,37,
,20519,37,0.029126405715942383
0.028024230152368546,20549,38,
0.02945118583738804,20599,38,
0.05116790533065796,20649,38,
0.020613551139831543,20699,38,
0.033059995621442795,20749,38,
0.022339176386594772,20799,38,
0.02939186431467533,20849,38,
0.032977521419525146,20899,38,
0.026927633211016655,20949,38,
0.0365469716489315,20999,38,
0.03857559710741043,21049,38,
,21059,38,0.029305720701813698
0.037662629038095474,21099,39,
0.022595634683966637,21149,39,
0.036965105682611465,21199,39,
0.03822193667292595,21249,39,
0.02331787720322609,21299,39,
0.059307411313056946,21349,39,
0.020943114534020424,21399,39,
0.0309622623026371,21449,39,
0.05048396438360214,21499,39,
0.026059657335281372,21549,39,
0.02178962342441082,21599,39,
,21599,39,0.0284722950309515
0.03724832832813263,21649,40,
0.0284771416336298,21699,40,
0.024350514635443687,21749,40,
0.03238850086927414,21799,40,
0.015272987075150013,21849,40,
0.03583546355366707,21899,40,
0.028709981590509415,21949,40,
0.021257834509015083,21999,40,
0.05215022340416908,22049,40,
0.028783615678548813,22099,40,
,22139,40,0.02858848124742508
0.03135780617594719,22149,41,
0.026484793052077293,22199,41,
0.01747334934771061,22249,41,
0.03425179794430733,22299,41,
0.023866422474384308,22349,41,
0.039299316704273224,22399,41,
0.023904314264655113,22449,41,
0.04236595332622528,22499,41,
0.024370959028601646,22549,41,
0.04942728579044342,22599,41,
0.02492416650056839,22649,41,
,22679,41,0.02878296934068203
0.030145546421408653,22699,42,
0.023042980581521988,22749,42,
0.02742026560008526,22799,42,
0.03306284174323082,22849,42,
0.029046284034848213,22899,42,
0.028960062190890312,22949,42,
0.03608059138059616,22999,42,
0.053505104035139084,23049,42,
0.026859933510422707,23099,42,
0.03452673181891441,23149,42,
0.03725801035761833,23199,42,
,23219,42,0.028494251891970634
0.01976045034825802,23249,43,
0.021132783964276314,23299,43,
0.05279018357396126,23349,43,
0.01602095738053322,23399,43,
0.03850091993808746,23449,43,
0.036914627999067307,23499,43,
0.02383449301123619,23549,43,
0.028315166011452675,23599,43,
0.03142615035176277,23649,43,
0.03261767700314522,23699,43,
0.03948628157377243,23749,43,
,23759,43,0.0280084777623415
0.04238118603825569,23799,44,
0.027479097247123718,23849,44,
0.033834490925073624,23899,44,
0.02716135047376156,23949,44,
0.029674453660845757,23999,44,
0.023532913997769356,24049,44,
0.04296012222766876,24099,44,
0.015814492478966713,24149,44,
0.02357812412083149,24199,44,
0.043867770582437515,24249,44,
0.026976153254508972,24299,44,
,24299,44,0.02835596166551113
0.0565623976290226,24349,45,
0.0320737361907959,24399,45,
0.022412845864892006,24449,45,
0.041191864758729935,24499,45,
0.02589041367173195,24549,45,
0.03535196930170059,24599,45,
0.038850732147693634,24649,45,
0.019826456904411316,24699,45,
0.037114083766937256,24749,45,
0.041317638009786606,24799,45,
,24839,45,0.0280530396848917
0.036305274814367294,24849,46,
0.0228587593883276,24899,46,
0.03707791864871979,24949,46,
0.04295237734913826,24999,46,
0.028014646843075752,25049,46,
0.04626207798719406,25099,46,
0.01727025769650936,25149,46,
0.0429835207760334,25199,46,
0.03316420316696167,25249,46,
0.018624119460582733,25299,46,
0.03766869381070137,25349,46,
,25379,46,0.028612768277525902
0.015852928161621094,25399,47,
0.03922209516167641,25449,47,
0.0212404765188694,25499,47,
0.03155199810862541,25549,47,
0.027962274849414825,25599,47,
0.024642949923872948,25649,47,
0.030721068382263184,25699,47,
0.02955147996544838,25749,47,
0.04059179499745369,25799,47,
0.03355712816119194,25849,47,
0.03836347535252571,25899,47,
,25919,47,0.028956377878785133
0.029820796102285385,25949,48,
0.017069628462195396,25999,48,
0.031747568398714066,26049,48,
0.02692372351884842,26099,48,
0.019201500341296196,26149,48,
0.042182520031929016,26199,48,
0.054304271936416626,26249,48,
0.025463392958045006,26299,48,
0.040235571563243866,26349,48,
0.02176416479051113,26399,48,
0.017380207777023315,26449,48,
,26459,48,0.028652513399720192
0.034039393067359924,26499,49,
0.0400402806699276,26549,49,
0.04530732333660126,26599,49,
0.03611563518643379,26649,49,
0.0293329618871212,26699,49,
0.0346183106303215,26749,49,
0.023343056440353394,26799,49,
0.013459374196827412,26849,49,
0.05635221675038338,26899,49,
0.04409942030906677,26949,49,
0.020870042964816093,26999,49,
,26999,49,0.028020614758133888

================
File: training/lightning_logs/version_4/hparams.yaml
================
{}

================
File: training/training-script-20240123-karras-edm.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel 
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--image-size', type=int, default=192)
    # datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = 'script-20240123'
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    model = poregen.models.PUNetUncond(64, dropout=0.2)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    module = poregen.models.KarrasModule(model, moduleconfig)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize)
    main(config, module)

================
File: training/training-script-20240124-ddpm-v2.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel 
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    basefilename = f'sample-width={image_size}'
    filename = f'{basefilename}-{{epoch:02d}}-{{valid_loss:.6f}}'
    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename=filename,
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=192)
    # datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = 'script-20240123'
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    image_size = args.image_size

    model = poregen.models.AkshahyNetUncond(64, dropout=0.2)
    moduleconfig = (poregen.
                    models.
                    ddpm.
                    v2.
                    DDPMModuleConfig.
                    from_classical_ddpm())
    module = (poregen.
              models.
              ddpm.
              v2.
              DDPMModule(model, moduleconfig))
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=image_size)
    main(config, module)

================
File: training/training-script-20240125-cascade.py
================
import pathlib
import argparse
import os
import re
import json

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"experimental"/"savedmodels"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    basefilename = f'sample-width={image_size}'
    filename = f'{basefilename}-{{epoch:02d}}-{{valid_loss:.6f}}'
    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename=filename,
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


def get_module(type, model, prev=None):
    if type == 'ddpmv1':
        scheduler = poregen.models.DDPMScheduler()
        if prev is None:
            module = poregen.models.DDPMModule(model,
                                               scheduler,
                                               conditional=False,
                                               loss_type="huber",
                                               loss_scaling="constant",
                                               loss_scale_factor=1.0)
        else:
            module = (poregen.models.DDPMModule.
                      load_from_checkpoint(prev,
                                           model=model,
                                           scheduler=scheduler,
                                           conditional=False,
                                           loss_type="huber",
                                           loss_scaling="constant",
                                           loss_scale_factor=1.0))
    else:
        if type == 'ddpmv2':
            moduleconfig = (poregen.
                            models.
                            ddpm.
                            v2.
                            DDPMModuleConfig.
                            from_classical_ddpm())
            module_cls = (poregen.
                          models.
                          ddpm.
                          v2.
                          DDPMModule)
        elif type == 'edm':
            moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
            module_cls = poregen.models.KarrasModule
        if prev is None:
            module = module_cls(model, moduleconfig)
        else:
            module = module_cls.load_from_checkpoint(prev,
                                                     model=model,
                                                     config=moduleconfig)
    return module


def find_lowest_loss_file(directory, basename):
    # Compile a regular expression pattern to match the file format
    # This pattern will also capture the valid_loss value for comparison
    pt = rf"^{re.escape(basename)}-epoch=\d+-valid_loss=(\d+\.\d+)\.ckpt$"
    pattern = re.compile(pt)

    lowest_loss = float('inf')  # Initialize with infinity
    lowest_loss_file = None  # Initialize the filename variable

    # Iterate through the files in the directory
    for filename in os.listdir(directory):
        match = pattern.match(filename)
        if match:
            # Extract valid_loss from the filename
            valid_loss = float(match.group(1))

            # Compare with the lowest_loss and update if it's lower
            if valid_loss < lowest_loss:
                lowest_loss = valid_loss
                lowest_loss_file = filename

    # Return the filename with the lowest valid_loss
    return lowest_loss_file


def parse_list(arg):
    try:
        # Convert the string to a list
        return json.loads(arg.replace('=', ':'))
    except json.JSONDecodeError:
        raise ValueError(f"Argument {arg} is not in the correct format")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--type', type=str, default='edm',
                        choices=['edm', 'ddpmv1', 'ddpmv2'])
    parser.add_argument('--image-sizes', type=str, default='[192]')
    parser.add_argument('--nums-epochs', type=str, default='[50]')
    # datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = 'script-20240123'
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    type = args.type
    image_sizes = parse_list(args.image_sizes)
    nums_epochs = parse_list(args.nums_epochs)

    iterator = enumerate(zip(image_sizes, nums_epochs))
    for i, (image_size, num_epochs) in iterator:
        if i == 0:
            prev = None
        else:
            directory = MODELSPATH/savefolderstr
            basefilename = f'sample-width={image_sizes[i-1]}'
            lowest_loss_file = find_lowest_loss_file(directory, basefilename)
            prev = MODELSPATH/savefolderstr/lowest_loss_file
        config = Config(datastr,
                        kindofdata,
                        savefolderstr,
                        image_size=image_size,
                        num_epochs=num_epochs)
        model = poregen.models.PUNetUncond(64, dropout=0.2)
        module = get_module(type, model, prev)
        main(config, module)

================
File: training/training-script-20240125-ddpm-v1.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"experimental"/"savedmodels"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel 
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='val_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=192)
    # datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = 'script-20240123'
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    image_size = args.image_size

    model = poregen.models.PUNetUncond(64, dropout=0.2)
    scheduler = poregen.models.DDPMScheduler()
    module = poregen.models.DDPMModule(model,
                                       scheduler,
                                       conditional=False,
                                       loss_type="huber",
                                       loss_scaling="constant",
                                       loss_scale_factor=128**2)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=image_size)
    main(config, module)

================
File: training/training-script-20240125-single.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"experimental"/"savedmodels"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel 
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    basefilename = f'sample-width={image_size}'
    filename = f'{basefilename}-{{epoch:02d}}-{{valid_loss:.6f}}'
    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename=filename,
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--type', type=str, default='edm',
                        choices=['edm', 'ddpmv1', 'ddpmv2'])
    parser.add_argument('--image-size', type=int, default=192)
    parser.add_argument('--num-epochs', type=int, default=50)
    # datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = 'script-20240123'
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    type = args.type
    image_size = args.image_size
    num_epochs = args.num_epochs

    model = poregen.models.PUNetUncond(64, dropout=0.2)
    if type == 'ddpmv2':
        moduleconfig = (poregen.
                        models.
                        ddpm.
                        v2.
                        DDPMModuleConfig.
                        from_classical_ddpm())
        module = (poregen.
                  models.
                  ddpm.
                  v2.
                  DDPMModule(model, moduleconfig))
    elif type == 'ddpmv1':
        scheduler = poregen.models.DDPMScheduler()
        module = poregen.models.DDPMModule(model,
                                           scheduler,
                                           conditional=False,
                                           loss_type="huber",
                                           loss_scaling="constant",
                                           loss_scale_factor=1.0)
    elif type == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
        module = poregen.models.KarrasModule(model, moduleconfig)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=image_size,
                    num_epochs=num_epochs)
    main(config, module)

================
File: training/training-script-20240222-karras-edm-all.py
================
import pathlib
import argparse
import os

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-4,
                 num_epochs: int = 100,
                 lr_scheduler: None | str = None):
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    files = [f
             for f in os.listdir(RAWDATAPATH/'eleven_sandstones')
             if f.endswith('binary.raw')]
    train_voxels = []
    valid_voxels = []
    for file in files:
        voxel = (poregen.
                 data.
                 binary_datasets.
                 load_binary_from_eleven_sandstones(
                     RAWDATAPATH/'eleven_sandstones'/file))
        split = int(voxel.shape[0]*config.psplit)
        train_voxels.append(voxel[:split])
        valid_voxels.append(voxel[split:])
        del voxel
    # train_voxel = voxel[:split, :, :]  # Separate in train voxel 
    # valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    # del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size
    dataset_cls = (poregen.
                   data.
                   binary_datasets.
                   SequenceOfVoxelsToSlicesDataset)
    train_dataset = dataset_cls(
        train_voxels,
        transform=transform,
        image_size=image_size)
    val_dataset = dataset_cls(
        valid_voxels,
        transform=transform,
        image_size=image_size)
    del train_voxels, valid_voxels
    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    # datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = 'script-20240123'
    args = parser.parse_args()
    savefolderstr = args.savefolderstr

    model = poregen.models.PUNetUncond(64, dropout=0.2)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    module = poregen.models.KarrasModule(model, moduleconfig)
    config = Config(savefolderstr)
    main(config, module)

================
File: training/training-script-20240222-karras-mnist.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"MNIST"/"raw"  # This leads to the MNIST data folder
MODELSPATH = MAINPATH/"experimental"/"savedmodels"


class UnlabeledMNISTDataset(torch.utils.data.Dataset):
    def __init__(self, mnist_dataset):
        self.mnist_dataset = mnist_dataset

    def __len__(self):
        return len(self.mnist_dataset)

    def __getitem__(self, idx):
        x, _ = self.mnist_dataset[idx]
        return x*2-1        # rescaled to range [-1,1] as done in Karras et. al


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['mnist']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'mnist':
        dataset = UnlabeledMNISTDataset(path)
    else:
        raise ValueError('Invalid kind of data.')
    num_train_dataset = int(len(dataset)*config.psplit)
    num_valid_dataset = len(dataset) - num_train_dataset
    train_dataset, val_dataset = torch.utils.data.random_split(
        dataset,
        [num_train_dataset, num_valid_dataset])
    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=config.batch_size,
        shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=config.batch_size,
        shuffle=False)
    del dataset

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['mnist'],
                        default='mnist')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    # datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = 'script-20240123'
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr

    model = poregen.models.AkshahyNetUncond(64, dropout=0.2)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    module = poregen.models.KarrasModule(model, moduleconfig)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr)
    main(config, module)

================
File: training/training-script-20240226-karras-edm-all-latent.py
================
import pathlib
import argparse
import os

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-4,
                 num_epochs: int = 100,
                 lr_scheduler: None | str = None):
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    files = [f
             for f in os.listdir(RAWDATAPATH/'eleven_sandstones')
             if f.endswith('binary.raw')]
    train_voxels = []
    valid_voxels = []
    for file in files:
        voxel = (poregen.
                 data.
                 binary_datasets.
                 load_binary_from_eleven_sandstones(
                     RAWDATAPATH/'eleven_sandstones'/file))
        split = int(voxel.shape[0]*config.psplit)
        train_voxels.append(voxel[:split])
        valid_voxels.append(voxel[split:])
        del voxel
    # train_voxel = voxel[:split, :, :]  # Separate in train voxel
    # valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    # del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size
    dataset_cls = (poregen.
                   data.
                   binary_datasets.
                   SequenceOfVoxelsToSlicesDataset)
    train_dataset = dataset_cls(
        train_voxels,
        transform=transform,
        image_size=image_size)
    val_dataset = dataset_cls(
        valid_voxels,
        transform=transform,
        image_size=image_size)
    del train_voxels, valid_voxels
    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--architecture', type=str, default='unet',
                        choices=['unet', 'transformer'])
    args = parser.parse_args()
    savefolderstr = args.savefolderstr

    if args.architecture == 'unet':
        model = poregen.models.PUNetUncond(64,
                                           dropout=0.2,
                                           channels=4)
    elif args.architecture == 'transformer':
        model = poregen.models.DiffusionTransformer(nchannels=4)
    vae_wrapper = poregen.models.load_autoencoder("tiny1")
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    module = poregen.models.KarrasModule(model,
                                         moduleconfig,
                                         autoencoder=vae_wrapper)
    config = Config(savefolderstr)
    main(config, module)

================
File: training/training-script-20240314-karras-edm-latent.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--image-size', type=int, default=192)
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.image_size

    model = poregen.models.PUNetUncond(64,
                                       dropout=0.2,
                                       channels=4)
    vae_wrapper = poregen.models.load_autoencoder("tiny1")
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    module = poregen.models.KarrasModule(model,
                                         moduleconfig,
                                         autoencoder=vae_wrapper)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize)
    main(config, module)

================
File: training/training-script-20240402-ocean-superres.py
================
import pathlib
import os

import torch
import torchvision.transforms.v2 as transforms
import lightning
import lightning.pytorch.callbacks as callbacks
import numpy as np
import netCDF4

import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH / "saveddata"
RESULTS2023PATH = DATAPATH / "raw" / "currents_southeast_2023"
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class CurrentsDataset(torch.utils.data.Dataset):
    """Custom Dataloader. Load each image at a time to avoid
    high memory usage"""
    def __init__(self, directory):
        self.directory = directory
        # SSH files
        self.files_2du = [f for f in os.listdir(directory)
                          if '2du' in f]
        # UV files
        self.files_fsd = [f for f in os.listdir(directory)
                          if 'fsd' in f]
        self.day_hours = self.extract_hours_by_day(self.files_2du)
        self.paths_2du = {f.split('_')[1] + '_' + f.split('_')[2]:
                          os.path.join(directory, f) for f in self.files_2du}
        self.paths_fsd = {f.split('_')[1] + '_' + f.split('_')[2]:
                          os.path.join(directory, f) for f in self.files_fsd}

    def extract_hours_by_day(self, strings):
        """Extrac the date and time from each data"""
        day_to_hours = {}
        for s in strings:
            parts = s.split('_')
            day = parts[1]
            hour = parts[2]
            if day not in day_to_hours:
                day_to_hours[day] = [hour]
            else:
                day_to_hours[day].append(hour)
        # Transform to list of (day, hour) tuples
        day_hours = [(day, hour)
                     for day, hours in day_to_hours.items()
                     for hour in hours]
        day_hours = sorted(day_hours)
        return day_hours

    def __len__(self):
        return len(self.day_hours)

    def __getitem__(self, idx):
        # Find the day and hour corresponding to idx
        # The data is ordered by time, so higher idx means later data
        day, hour = self.day_hours[idx]
        filepath_2du = self.paths_2du[day + '_' + hour]
        filepath_fsd = self.paths_fsd[day + '_' + hour]

        # Load data
        with (netCDF4.Dataset(filepath_2du, "r") as nc_dataset_2du,
              netCDF4.Dataset(filepath_fsd, "r") as nc_dataset_fsd):
            u_velocity = nc_dataset_2du.variables['u_velocity'][0, 0, :, :]
            v_velocity = nc_dataset_2du.variables['v_velocity'][0, 0, :, :]
            ssh = nc_dataset_fsd.variables['ssh'][0, :, :]
            mask = np.ma.getmask(u_velocity)
        # Convert to torch tensors
        u_tensor = torch.tensor(u_velocity.filled(np.nan),
                                dtype=torch.float32)
        v_tensor = torch.tensor(v_velocity.filled(np.nan),
                                dtype=torch.float32)
        ssh_tensor = torch.tensor(ssh.filled(np.nan),
                                  dtype=torch.float32)

        # Stack into a single tensor of shape [3, H, W]
        combined_tensor = torch.stack([u_tensor, v_tensor, ssh_tensor])
        # Mask will be True for invalid data, False for valid data
    
        mask_tensor = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)
        # Prepare batimetry tensor
        # Extract batimetry
        batimetry_path = os.path.join(
            self.directory,
            'batimetria_cortada_interpolada_LSE36.nc')
        batimetry_dataset = netCDF4.Dataset(batimetry_path, 'r')
        bat = batimetry_dataset.variables['batim'][:]
        bat_tensor = torch.tensor(bat.filled(np.nan),
                                  dtype=torch.float32).unsqueeze(0)
        bat_tensor = bat_tensor/(10**4)  # Rough normalization
        return mask_tensor, bat_tensor, combined_tensor


class CurrentsSuperResolutionDataset(CurrentsDataset):
    def __init__(self, directory, crop_size=128, downscale_factor=4):
        super().__init__(directory)
        # crop the image and downscale
        self.crop_size = crop_size
        self.downscale_factor = downscale_factor
        self.transform_hr = transforms.Compose([
                                transforms.RandomCrop(crop_size)])
        self.transform_lr = transforms.Compose([
                                transforms.ToTensor()])

    def __getitem__(self, idx):
        bat_tensor, mask_tensor, combined_tensor = super().__getitem__(idx)
        full_tensor = torch.cat([combined_tensor,
                                 mask_tensor,
                                 bat_tensor])
        full_tensor = torch.nan_to_num(full_tensor)
        crop = self.transform_hr(full_tensor)
        hr_image = crop[:3]

        # Create LR image by blurring and then downscaling
        lr_image = self.transform_lr(hr_image)  # Apply blur
        lr_image = torch.nn.functional.interpolate(
            lr_image.unsqueeze(0),
            scale_factor=1/self.downscale_factor,
            mode='bilinear',
            align_corners=False).squeeze(0)

        # Get back to the original size
        lr_image = torch.nn.functional.interpolate(
            lr_image.unsqueeze(0),
            size=crop.shape[1:],
            mode='bilinear',
            align_corners=False).squeeze(0)

        mask = crop[-1].unsqueeze(0)
        return lr_image, crop, mask


def train():
    dataset = CurrentsSuperResolutionDataset(RESULTS2023PATH)

    def split_dataset_from_proportions(dataset, proportions):
        lengths = [int(p * len(dataset)) for p in proportions]
        lengths[-1] = len(dataset) - sum(lengths[:-1])
        return torch.utils.data.random_split(dataset, lengths)

    batch_size = 32

    train_dataset, val_dataset = split_dataset_from_proportions(
        dataset, [0.8, 0.2])
    train_dataloader = torch.utils.data.DataLoader(train_dataset,
                                                   batch_size=batch_size,
                                                   shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(val_dataset,
                                                 batch_size=batch_size,
                                                 shuffle=False)
    model = poregen.models.PUNetCond(64,
                                     channels=3,
                                     conditional_channels=5)
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    module = poregen.models.KarrasModule(model=model,
                                         config=moduleconfig,
                                         conditional=True,
                                         masked=True)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/"ocean-superres-0402",
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )
    trainer = lightning.Trainer(max_epochs=100,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    train()

================
File: training/training-script-20240410-karras-edm-3d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 100,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel 
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        subslice=image_size)
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        subslice=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=23)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=23)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--image-size', type=int, default=32)
    parser.add_argument('--checkpoint', type=str, default='')
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.image_size
    checkpoint = args.checkpoint

    model = poregen.models.PUNet3DUncond(32,
                                         dropout=0.2)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    if checkpoint != '':
        module = poregen.models.KarrasModule.load_from_checkpoint(
            MAINPATH/checkpoint,
            model=model,
            config=moduleconfig
        )
    else:
        module = poregen.models.KarrasModule(model,
                                             moduleconfig)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=2*1e-4)
    main(config, module)

================
File: training/training-script-20240416-pore-superres.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


def lower_resolution(image, factor=4):
    # subsample the image
    image = image[..., ::factor, ::factor]
    # return to original size
    image = torch.nn.functional.interpolate(image.unsqueeze(0),
                                            scale_factor=factor,
                                            mode='nearest').squeeze(0)
    return image


def lower_resolution_2(image, downscale_factor=4):
    lr_image = torch.nn.functional.interpolate(
        image.unsqueeze(0),
        scale_factor=1/downscale_factor,
        mode='bilinear',
        align_corners=False).squeeze(0)

    # Get back to the original size
    lr_image = torch.nn.functional.interpolate(
        lr_image.unsqueeze(0),
        size=image.shape[1:],
        mode='bilinear',
        align_corners=False).squeeze(0)

    lr_image = torch.round(lr_image)
    return lr_image


class LowHighResDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, downscale_factor=4):
        self.dataset = dataset
        self.downscale_factor = downscale_factor

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image = self.dataset[idx]
        image_low = lower_resolution_2(image,
                                       downscale_factor=self.downscale_factor)
        return image, image_low


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 100,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    transform = poregen.data.get_standard_binary_transforms()
    train_dataset = poregen.data.GrayVoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.GrayVoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataset_lowres = LowHighResDataset(train_dataset,
                                             downscale_factor=8)
    val_dataset_lowres = LowHighResDataset(val_dataset,
                                           downscale_factor=8)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset_lowres, batch_size=batch_size, shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset_lowres, batch_size=batch_size, shuffle=False)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=128)
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.image_size

    model = poregen.models.PUNetCond(64,
                                     channels=1,
                                     conditional_channels=1)
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    module = poregen.models.KarrasModule(model=model,
                                         config=moduleconfig,
                                         conditional=True)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3)
    main(config, module)

================
File: training/training-script-20240418-ocean-poormangencast.py
================
import pathlib
import os

import torch
import torchvision.transforms.v2 as transforms
import lightning
import numpy as np
import lightning.pytorch.callbacks as callbacks
import netCDF4

import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH / "saveddata"
RESULTS2023PATH = DATAPATH / "raw" / "currents_southeast_2023"
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class ContiguousCurrentsDataset(torch.utils.data.Dataset):
    def __init__(self,
                 directory,
                 subwindow=None,
                 D=2,
                 transform=None):
        self.directory = directory
        self.subwindow = subwindow
        self.D = D
        self.files_2du = [f for f in os.listdir(directory) if '2du' in f]
        self.files_fsd = [f for f in os.listdir(directory) if 'fsd' in f]
        self.paths_2du = {f.split('_')[1] + '_' + f.split('_')[2]:
                          os.path.join(directory, f) for f in self.files_2du}
        self.paths_fsd = {f.split('_')[1] + '_' + f.split('_')[2]:
                          os.path.join(directory, f) for f in self.files_fsd}
        self.day_hours, self.hours_since_year_start = \
            self.extract_hours_by_day(self.files_2du)
        self.transform = transform
        self.valid_indices = self.calculate_valid_indices()

    def extract_hours_by_day(self, strings):
        day_to_hours = {}
        for s in strings:
            parts = s.split('_')
            day, hour = parts[1], parts[2]
            if day not in day_to_hours:
                day_to_hours[day] = []
            day_to_hours[day].append(hour)
        day_hours = sorted((day, hour)
                           for day, hours in day_to_hours.items()
                           for hour in hours)
        hours_since_start = {f'{day}_{hour}':
                             24 * int(day) + int(hour)
                             for day, hours in day_to_hours.items()
                             for hour in hours}
        return day_hours, hours_since_start

    def calculate_valid_indices(self):
        valid_indices = []
        for i in range(len(self.day_hours) - self.D + 1):
            start_day, start_hour = self.day_hours[i]
            start_hour_index = self.hours_since_year_start[
                f'{start_day}_{start_hour}']
            expected_end_hour_index = start_hour_index + self.D - 1
            end_day, end_hour = self.day_hours[i + self.D - 1]
            if (self.hours_since_year_start.get(
                    f'{end_day}_{end_hour}', -1
                    ) == expected_end_hour_index):
                if int(end_day) == int(start_day):
                    valid_indices.append(i)
        return valid_indices

    def __len__(self):
        return len(self.valid_indices)

    def __getitem__(self, idx, subwindow=None):
        if subwindow is None:
            subwindow = self.subwindow
        sequence_data = []
        actual_idx = self.valid_indices[idx]

        for offset in range(self.D):
            day, hour = self.day_hours[actual_idx + offset]
            filepath_2du = self.paths_2du[f'{day}_{hour}']
            filepath_fsd = self.paths_fsd[f'{day}_{hour}']

            with (netCDF4.Dataset(filepath_2du, "r") as nc_dataset_2du,
                  netCDF4.Dataset(filepath_fsd, "r") as nc_dataset_fsd):
                latitudes = nc_dataset_2du.variables['Latitude'][:]
                longitudes = nc_dataset_2du.variables['Longitude'][:]
                lat_idx, lon_idx = self.get_indices_from_proportion(
                    latitudes, longitudes, subwindow)

                u_velocity = nc_dataset_2du.variables['u_velocity'][
                    0, 0, lat_idx[0]:lat_idx[1], lon_idx[0]:lon_idx[1]]
                v_velocity = nc_dataset_2du.variables['v_velocity'][
                    0, 0, lat_idx[0]:lat_idx[1], lon_idx[0]:lon_idx[1]]
                ssh = nc_dataset_fsd.variables['ssh'][
                    0, lat_idx[0]:lat_idx[1], lon_idx[0]:lon_idx[1]]
                mask = np.ma.getmask(u_velocity)
                if len(mask.shape) == 0:
                    mask = np.zeros_like(u_velocity, dtype=bool)
                sequence_data.append((u_velocity, v_velocity, ssh, mask))

        tensors = [self.prepare_tensors(*data) for data in sequence_data]

        # Make tensor contiguous in the first dimension
        tensors = list(zip(*tensors))
        tensors = [torch.stack(t) for t in tensors]

        if self.transform:
            tensors = [self.transform(t) for t in tensors]
        return tensors, (day, hour)

    def get_indices_from_proportion(self, latitudes, longitudes, subwindow):
        if subwindow:
            lat_range = [int(subwindow[0][0] * len(latitudes)),
                         int(subwindow[0][1] * len(latitudes))]
            lon_range = [int(subwindow[1][0] * len(longitudes)),
                         int(subwindow[1][1] * len(longitudes))]
            return lat_range, lon_range
        return [0, len(latitudes)], [0, len(longitudes)]

    def prepare_tensors(self, u_velocity, v_velocity, ssh, mask):
        u_tensor = torch.tensor(u_velocity.filled(0.0), dtype=torch.float32)
        v_tensor = torch.tensor(v_velocity.filled(0.0), dtype=torch.float32)
        ssh_tensor = torch.tensor(ssh.filled(0.0), dtype=torch.float32)
        combined_tensor = torch.stack([u_tensor, v_tensor, ssh_tensor])
        mask_tensor = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)

        # Remove any possible nans, converting to 0.0
        combined_tensor = torch.nan_to_num(combined_tensor, nan=0.0)
        mask_tensor = torch.nan_to_num(mask_tensor, nan=1.0)

        return mask_tensor, combined_tensor


class ContiguousCurrentsDatasetAutoregressive(ContiguousCurrentsDataset):
    def __getitem__(self, idx, subwindow=None):
        tensors, (day, hour) = super().__getitem__(idx, subwindow)
        x = tensors[1][-1]
        y = tensors[1][-2]
        mask = tensors[0][-1]
        return x, y, mask


class MeanEncoder(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x, y):
        return self.decode(self.encode(x, y), y)

    def encode(self, x, y):
        return x - y

    def decode(self, z, y):
        return z + y


def train():
    transform = transforms.Compose([transforms.RandomCrop((128, 128))])
    dataset = ContiguousCurrentsDatasetAutoregressive(RESULTS2023PATH,
                                                      subwindow=[[0.0, 0.5],
                                                                 [0.5, 1.0]],
                                                      transform=transform)
    x, y, mask = dataset[20]

    def split_dataset_from_proportions(dataset, proportions):
        lengths = [int(p * len(dataset)) for p in proportions]
        lengths[-1] = len(dataset) - sum(lengths[:-1])
        return torch.utils.data.random_split(dataset, lengths)

    train_dataset, val_dataset = split_dataset_from_proportions(
        dataset, [0.8, 0.2])

    batch_size = 32
    train_dataloader = torch.utils.data.DataLoader(train_dataset,
                                                   batch_size=batch_size,
                                                   shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(val_dataset,
                                                 batch_size=batch_size)
    encoder = MeanEncoder()
    model = poregen.models.PUNetCond(64,
                                     channels=3,
                                     conditional_channels=3)
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    module = poregen.models.KarrasModule(model=model,
                                         config=moduleconfig,
                                         conditional=True,
                                         masked=True,
                                         autoencoder=encoder,
                                         autoencoder_conditional=True)
    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/"ocean-poorgencast-0424",
        filename='sample-{epoch:02d}-{valid_loss:.8f}',
        save_top_k=5,
        mode='min',
    )

    trainer = lightning.Trainer(max_epochs=200,
                                gradient_clip_val=0.5,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    train()

================
File: training/training-script-20240418-pore-superres.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


def lower_resolution(image, factor=4):
    # subsample the image
    image = image[..., ::factor, ::factor]
    # return to original size
    image = torch.nn.functional.interpolate(image.unsqueeze(0),
                                            scale_factor=factor,
                                            mode='nearest').squeeze(0)
    return image


def lower_resolution_2(image, downscale_factor=4):
    lr_image = torch.nn.functional.interpolate(
        image.unsqueeze(0),
        scale_factor=1/downscale_factor,
        mode='bilinear',
        align_corners=False).squeeze(0)

    # Get back to the original size
    lr_image = torch.nn.functional.interpolate(
        lr_image.unsqueeze(0),
        size=image.shape[1:],
        mode='bilinear',
        align_corners=False).squeeze(0)

    lr_image = torch.round(lr_image)
    return lr_image


class LowHighResDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, downscale_factor=4):
        self.dataset = dataset
        self.downscale_factor = downscale_factor

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image = self.dataset[idx]
        image_low = lower_resolution_2(image,
                                       downscale_factor=self.downscale_factor)
        return image_low, image


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 100,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    transform = poregen.data.get_standard_binary_transforms()
    train_dataset = poregen.data.GrayVoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.GrayVoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataset_lowres = LowHighResDataset(train_dataset,
                                             downscale_factor=8)
    val_dataset_lowres = LowHighResDataset(val_dataset,
                                           downscale_factor=8)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset_lowres, batch_size=batch_size, shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset_lowres, batch_size=batch_size, shuffle=False)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.Adam(module.parameters(),
                                        lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=128)
    args = parser.parse_args()
    datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.image_size

    model = poregen.models.PUNetCond(64,
                                     channels=1,
                                     conditional_channels=1)
    vae_wrapper = poregen.models.load_autoencoder("conditional")
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    module = poregen.models.KarrasModule(model=model,
                                         config=moduleconfig,
                                         autoencoder=vae_wrapper,
                                         autoencoder_conditional=True)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3)
    main(config, module)

================
File: training/training-script-20240430-autoencoder3d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 10,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    # image_size = config.image_size
    batch_size = config.batch_size

    transform = poregen.data.get_standard_binary_transforms()
    train_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=[32, 64, 64]
        )
    val_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=[32, 64, 64])

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=128)
    args = parser.parse_args()
    datastr = 'berea/Berea_2d25um_binary.raw'
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.image_size

    vae_model = poregen.models.autoencoder3d3.VAE()
    vae_module = poregen.models.AutoencoderModule(model=vae_model)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3)
    main(config, vae_module)

================
File: training/training-script-20240501-autoencoder2d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 40,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    transform = poregen.data.get_standard_binary_transforms()

    train_dataset = poregen.data.GrayVoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.GrayVoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)

    vae_model.save_pretrained(
        save_directory=MAINPATH/"savedmodels/autoencoders/berea2dvae20240502-2")
    # TODO: save the best valid loss


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=128)
    args = parser.parse_args()
    datastr = 'berea/Berea_2d25um_binary.raw'
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.image_size

    vae_model = poregen.models.nets.autoencoderkl.AutoencoderKL(
        in_channels=1, out_channels=1
        )
    vae_module = poregen.models.autoencoder.AutoencoderModule(model=vae_model)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3)
    main(config, vae_module)

================
File: training/training-script-20240502-4-autoencoder2d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 20,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    transform = poregen.data.get_standard_binary_transforms()

    train_dataset = poregen.data.GrayVoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.GrayVoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)

    vae_model.save_pretrained(
        save_directory=MAINPATH/"savedmodels/autoencoders/berea2dvae20240502-4"
        )
    # TODO: save the best valid loss


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=128)
    args = parser.parse_args()
    datastr = 'berea/Berea_2d25um_binary.raw'
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = 'berea2dvae20240502-4'
    imagesize = args.image_size

    vae_model = poregen.models.nets.autoencoderkl.AutoencoderKL(
        in_channels=1, out_channels=1
        )
    vae_module = poregen.models.autoencoder.AutoencoderModule(model=vae_model,
                                                              kl_weight=1e-6)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3)
    main(config, vae_module)

================
File: training/training-script-20240503-autoencoder2d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 30,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    transform = poregen.data.get_standard_binary_transforms()

    train_dataset = poregen.data.GrayVoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.GrayVoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)

    vae_model.save_pretrained(
        save_directory=MAINPATH/"savedmodels/experimental/[pore]-[2024-05-03]-[bps]-[berea2dvae-l1]"
        )
    # TODO: save the best valid loss


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=128)
    args = parser.parse_args()
    datastr = 'berea/Berea_2d25um_binary.raw'
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = '[pore]-[2024-05-03]-[bps]-[berea2dvae-l1]'
    imagesize = args.image_size
    checkpoint = (
        'savedmodels/experimental/[pore]-[2024-05-03]-[bps]-[berea2dvae-l1-ckpt]/sample-epoch=29-valid_loss=0.001575.ckpt'
    )

    vae_model = poregen.models.nets.autoencoderkl.AutoencoderKL(
        in_channels=1, out_channels=1
        )
    vae_module = (
        poregen.models.autoencoder.AutoencoderModule.load_from_checkpoint(
            model=vae_model,
            checkpoint_path=MAINPATH/checkpoint)
    )

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3)
    main(config, vae_module)

================
File: training/training-script-20240506-karras-edm-punetb.py
================
import pathlib
import argparse

import torch
import lightning
# from lightning.pytorch.tuner.tuning import Tuner
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
        )

    # find hyperparameters
    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    # tuner = Tuner(trainer)
    # module.lr = config.learning_rate
    # tuner.lr_find(module)
    # batch_size = tuner.scale_batch_size(module)
    batch_size = config.batch_size

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=23)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=23)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--imagesize', type=int, default=192)
    datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    # savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    model = poregen.models.PUNetBUncond(64, dropout=0.2)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    module = poregen.models.KarrasModule(model, moduleconfig)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    num_epochs=50)
    main(config, module)

================
File: training/training-script-20240509-autoencoder2d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 20,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    transform = poregen.data.get_standard_binary_transforms()

    train_dataset = poregen.data.GrayVoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.GrayVoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)

    vae_model.save_pretrained(
        save_directory=(MAINPATH/'savedmodels/experimental' /
                        '[pore]-[2024-05-09]-[bps]-[2dvae-l2-8x-normloss]')
        )
    # TODO: save the best valid loss


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=128)
    args = parser.parse_args()
    datastr = 'berea/Berea_2d25um_binary.raw'
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = 'berea2dvae20240502-3'
    imagesize = args.image_size

    vae_model = poregen.models.nets.autoencoderkl.AutoencoderKL(
        in_channels=1, out_channels=1
        )
    vae_module = poregen.models.autoencoder.AutoencoderModule(model=vae_model,
                                                              kl_weight=1e-6)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3)
    main(config, vae_module)

================
File: training/training-script-20240513-autoencoder_ldm2d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 10,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    transform = poregen.data.get_standard_binary_transforms()

    train_dataset = poregen.data.GrayVoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.GrayVoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='val/rec_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{val/rec_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    vae_model.optimizer = torch.optim.AdamW(module.parameters(),
                                            lr=config.learning_rate)
    vae_model.learning_rate = config.learning_rate
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=128)
    args = parser.parse_args()
    datastr = 'berea/Berea_2d25um_binary.raw'
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = '[pore]-[2024-05-13]-[bps]-[ldmvae2d]'
    imagesize = args.image_size

    lossconfig = poregen.models.nets.autoencoderldm2d.lossconfig()
    ddconfig = poregen.models.nets.autoencoderldm2d.ddconfig()

    vae_model = poregen.models.nets.autoencoderldm2d.AutoencoderKL(ddconfig,
                                                                   lossconfig)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3)

    main(config, vae_model)

================
File: training/training-script-20240514-autoencoder_ldm3d.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models

torch.cuda.empty_cache()

CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 20,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # image_size = config.image_size
    batch_size = config.batch_size

    transform = poregen.data.get_standard_binary_transforms()

    train_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=32)
    val_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=32)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='val/rec_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{val/rec_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    vae_model.optimizer = torch.optim.AdamW(module.parameters(),
                                            lr=config.learning_rate)
    vae_model.learning_rate = config.learning_rate
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=128)
    args = parser.parse_args()
    datastr = 'berea/Berea_2d25um_binary.raw'
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = '[pore]-[2024-05-14]-[bps]-[ldmvae3d]'
    imagesize = args.image_size

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig()
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig()

    # vae_model = poregen.models.nets.autoencoderldm3d.AutoencoderKL(ddconfig,
    #                                                                lossconfig)
    checkpoint = (MAINPATH/'savedmodels/experimental' /
                  '[pore]-[2024-05-14]-[bps]-[ldmvae3d]' /
                  'sample-epoch=09-val/rec_loss=0.020127.ckpt')

    vae_model = (
        poregen.models.nets.autoencoderldm3d.AutoencoderKL
        .load_from_checkpoint(
            checkpoint, ddconfig=ddconfig, lossconfig=lossconfig
            )
    )

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3)

    main(config, vae_model)

================
File: training/training-script-20240514-karras-latent_diff1-punetb.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 30,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.GrayVoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.GrayVoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--imagesize', type=int, default=192)
    datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    model = poregen.models.PUNetBUncond(64, dropout=0.2, channels=4)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    vae_wrapper = poregen.models.load_autoencoder(
        "our_kl",
        path=(MAINPATH/'savedmodels/experimental' /
              '[pore]-[2024-05-09]-[bps]-[2dvae-l2-8x]')
    )
    checkpoint = (MAINPATH/'savedmodels/experimental' /
                  '[pore]-[2024-05-14]-[bps]-[bereapunetb-latent1]' /
                  'sample-epoch=29-valid_loss=0.444418.ckpt')

    module = poregen.models.KarrasModule.load_from_checkpoint(
        checkpoint,
        model=model,
        config=moduleconfig,
        autoencoder=vae_wrapper)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize)
    main(config, module)

# this script is for the 8x diff vae w. unnormalized rec_loss

================
File: training/training-script-20240514-karras-latent_diff2-punetb.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 30,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.GrayVoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.GrayVoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--imagesize', type=int, default=192)
    datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    model = poregen.models.PUNetBUncond(64, dropout=0.2, channels=4)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    vae_wrapper = poregen.models.load_autoencoder(
        "our_kl",
        path=(MAINPATH/'savedmodels/experimental' /
              '[pore]-[2024-05-09]-[bps]-[2dvae-l2-8x-normloss]')
    )

    checkpoint = (MAINPATH/'savedmodels/experimental/[pore]-[2024-05-15]-[bps]-[bereapunetb-latent2]/sample-epoch=28-valid_loss=0.411229.ckpt')

    module = poregen.models.KarrasModule.load_from_checkpoint(
        checkpoint,
        model=model,
        config=moduleconfig,
        autoencoder=vae_wrapper)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize)
    main(config, module)

# this script is for the 8x diff vae w. normalized rec_loss

================
File: training/training-script-20240520-autoencoder_ldm3d-a100.py
================
import pathlib
import argparse

import torch
# import numpy as np
import lightning
from lightning.pytorch.tuner.tuning import Tuner
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models

torch.cuda.empty_cache()

CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 64,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # image_size = config.image_size
    batch_size = config.batch_size
    image_size = config.image_size

    transform = poregen.data.get_standard_binary_transforms()

    train_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=image_size)
    val_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=255)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False, num_workers=255)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='val/rec_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{val/rec_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                # devices=1,
                                strategy="ddp",
                                fast_dev_run=False)

    # tuner = Tuner(trainer)
    module.learning_rate = config.learning_rate
    # tuner.lr_find(module)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)

    dataloader_size = len(train_dataloader)
    num_warmup_steps = 10*dataloader_size
    num_cycles = 5
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))
    dataloader_size = len(train_dataloader)

    torch.set_float32_matmul_precision('medium')

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


# class TemporaryModel(poregen.models.nets.MLPUncond):
#     def forward(self, x, t):
#         oldshape = list(x.shape)
#         newshape = np.prod(oldshape[1:])
#         x = super().forward(x.reshape(-1, newshape), t)
#         x = x.reshape(*oldshape)
#         return x


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=64)
    args = parser.parse_args()
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # datastr = args.datastr
    kindofdata = args.kindofdata
    # savefolderstr = '[pore]-[2024-05-14]-[bps]-[ldmvae3d]'
    savefolderstr = args.savefolderstr
    imagesize = args.image_size

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(
        kl_weight=1.0)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        ch=32,
        ch_mult=(1,2,2),
        resolution=imagesize,
        dropout=0.1)

    vae_model = poregen.models.nets.autoencoderldm3d.AutoencoderKL(ddconfig,
                                                                   lossconfig)
    # checkpoint = (MAINPATH/'savedmodels/experimental' /
    #               '[pore]-[2024-05-14]-[bps]-[ldmvae3d]' /
    #               'sample-epoch=09-val/rec_loss=0.020127.ckpt')

    # vae_model = (
    #     poregen.models.nets.autoencoderldm3d.AutoencoderKL
    #     .load_from_checkpoint(
    #         checkpoint, ddconfig=ddconfig, lossconfig=lossconfig
    #         )
    # )

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3,
                    batch_size=16,
                    num_epochs=150)

    main(config, vae_model)

================
File: training/training-script-20240520-karras-edm-3d-a100.py
================
import pathlib
import argparse

import numpy as np
import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 100):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs


def main(config, module):
    path = config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel 
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        subslice=[image_size, image_size, image_size])
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        subslice=[image_size, image_size, image_size])

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=23)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=23)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    # x = next(iter(train_dataloader))
    # t = torch.rand((config.batch_size))
    # y = module.model(x, t)
    # loss = y.sum()
    # loss.backward()
    # for name, param in module.model.named_parameters():
    #     if param.grad is None:
    #         print(name, param.grad is None)
    # print('---'*10)
    # for name, param in module.model.named_parameters():
    #     if param.grad is not None:
    #         print(name, param.grad is None)
    # raise KeyError

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    dataloader_size = len(train_dataloader)
    num_warmup_steps = 10*dataloader_size
    num_cycles = 5
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))
    dataloader_size = len(train_dataloader)

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                devices=1,
                                strategy="ddp",
                                fast_dev_run=True)

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


class TemporaryModel(poregen.models.nets.MLPUncond):
    def forward(self, x, t):
        oldshape = list(x.shape)
        newshape = np.prod(oldshape[1:])
        x = super().forward(x.reshape(-1, newshape), t)
        x = x.reshape(*oldshape)
        return x


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--checkpoint', type=str, default='')
    args = parser.parse_args()
    datastr = \
        MAINPATH/"saveddata/raw/berea/Berea_2d25um_binary.raw"
    kindofdata = 'eleven'
    savefolderstr = '20240426-berea-3d-a100'
    imagesize = 4
    checkpoint = args.checkpoint

    model = poregen.models.PUNet3DBUncond(16, dropout=0.2)

    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    if checkpoint != '':
        module = poregen.models.KarrasModule.load_from_checkpoint(
            MAINPATH/checkpoint,
            model=model,
            config=moduleconfig
        )
    else:
        module = poregen.models.KarrasModule(model,
                                             moduleconfig)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    batch_size=2,
                    learning_rate=2*1e-4,
                    num_epochs=210)
    main(config, module)

================
File: training/training-script-20240520-karras-ldm3d-a100.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 voxel_size: int = 32,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 30,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.voxel_size = voxel_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    voxel_size = config.voxel_size
    batch_size = config.batch_size

    train_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=voxel_size)
    val_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=voxel_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=255)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=255)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 1
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))
    dataloader_size = len(train_dataloader)

    torch.set_float32_matmul_precision('medium')

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                # devices=1,
                                strategy="ddp",
                                fast_dev_run=False)

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--voxelsize', type=int, default=64)
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    # imagesize = args.imagesize
    voxel_size = args.voxelsize

    model = poregen.models.PUNet3DBUncond(64, dropout=0.2, channels=4)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    checkpoint_path=(MAINPATH/'savedmodels/experimental/[pore]-[2024-06-06]-[bps]-[ldmvae3d-64]/sample-epoch=130-val/rec_loss=0.008684.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(
        kl_weight=1.0)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        ch=32,
        ch_mult=(1,2,2),
        resolution=voxel_size,
        dropout=0.1)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    # checkpoint = (MAINPATH/'savedmodels/experimental/[pore]-[2024-05-20]-[bps]-[berealdm3d]/sample-epoch=29-valid_loss=7.609305.ckpt')

    # module = poregen.models.KarrasModule.load_from_checkpoint(
    #     checkpoint,
    #     model=model,
    #     config=moduleconfig,
    #     autoencoder=vae_module)

    module = poregen.models.KarrasModule(
        model=model,
        config=moduleconfig,
        autoencoder=vae_module)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    voxel_size=voxel_size,
                    learning_rate=1e-3,
                    batch_size=100,
                    num_epochs=200)
    
    main(config, module)

================
File: training/training-script-20240521-karras-ldm3d-a100-norm.py
================
import pathlib
import argparse

import torch
import lightning
from lightning.pytorch.tuner.tuning import Tuner
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 voxel_size: int = 32,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 30,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.voxel_size = voxel_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def compute_mean_and_variance(dataloader):
    all_samples = []
    for batch in dataloader:
        # batch = batch.to(vae_module.device)
        # batch = batch.cuda()          # this also doesnt work
        encoded_batch = vae_module.encode(batch)
        all_samples.extend(encoded_batch)
    subset_tensor = torch.cat(all_samples)
    mean = torch.mean(subset_tensor, dim=0, keepdims=True)
    std = torch.std(subset_tensor, dim=0, keepdims=True)
    return mean, std


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    voxel_size = config.voxel_size
    batch_size = config.batch_size

    train_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=voxel_size)
    val_dataset = poregen.data.GrayVoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=voxel_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=255)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=255)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    # normalize latent space

    mean, std = compute_mean_and_variance(train_dataloader)
    module.data_mean = mean
    module.data_std = std
    torch.save(mean, MAINPATH/'savedmodels/experimental/mean')
    torch.save(std, MAINPATH/'savedmodels/experimental/std')

    # mean = torch.load(MAINPATH/'mean')
    # std = torch.load(MAINPATH/'std')
    # module.data_mean = mean
    # module.data_std = std           # if loading from checkpoint



    torch.set_float32_matmul_precision('high')

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                # devices=1,
                                strategy="ddp",
                                fast_dev_run=False)

    tuner = Tuner(trainer)
    module.lr = config.learning_rate
    tuner.lr_find(module,
                  train_dataloaders=train_dataloader)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=module.lr)
    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 1
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--voxelsize', type=int, default=32)
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    # imagesize = args.imagesize
    voxel_size = args.voxelsize

    model = poregen.models.PUNet3DBUncond(64, dropout=0.2, channels=4)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-05-20]-[bps]-[ldmvae3d-l2]/sample-epoch=29-val/rec_loss=0.006102.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig()
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(resolution=voxel_size)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    # checkpoint = (MAINPATH/'savedmodels/experimental/[pore]-[2024-05-21]-[bps]-[berealdm3d-tuner]/sample-epoch=99-valid_loss=2.629776.ckpt')

    # module = poregen.models.KarrasModule.load_from_checkpoint(
    #     checkpoint,
    #     model=model,
    #     config=moduleconfig,
    #     autoencoder=vae_module)

    module = poregen.models.KarrasModule(
        model=model,
        config=moduleconfig,
        autoencoder=vae_module)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    voxel_size=voxel_size,
                    learning_rate=2*1e-4,
                    num_epochs=200)

    main(config, module)

================
File: training/training-script-20240521-poormangencast-cond.py
================
import pathlib
import os

import torch
import torchvision.transforms.v2 as transforms
import lightning
import numpy as np
import lightning.pytorch.callbacks as callbacks
import netCDF4

import poregen.models
import poregen.dataloaders

CURRENTPATH = pathlib.Path(__file__).parent.absolute()

MAINPATH = 'C:\\Users\\ntana\\poregen\\poregen'

RESULTS2023PATH = 'C:\\Users\\ntana\\Project_LABMA\\OceanData\\resultados_2023'

DATAPATH = MAINPATH + "\\saveddata"
# RESULTS2023PATH = DATAPATH / "raw" / "currents_southeast_2023"
MODELSPATH = MAINPATH + "\\savedmodels\\experimental"

"""CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH / "saveddata"
RESULTS2023PATH = DATAPATH / "raw" / "currents_southeast_2023"
MODELSPATH = MAINPATH/"savedmodels"/"experimental"""


class ContiguousCurrentsDataset(torch.utils.data.Dataset):
    def __init__(self,
                 directory,
                 subwindow=None,
                 D=3,
                 transform=None,
                 skip=1):
        self.directory = directory
        self.subwindow = subwindow
        self.D = D
        if skip == 0:
            skip += 1
            skip += 1
        self.skip = skip
        self.files_2du = sorted([f
                                 for f in os.listdir(directory)
                                 if '2du' in f])[::skip]
        self.files_fsd = sorted([f
                                 for f in os.listdir(directory)
                                 if 'fsd' in f])[::skip]
        self.paths_2du = {f.split('_')[1] + '_' + f.split('_')[2]:
                          os.path.join(directory, f) for f in self.files_2du}
        self.paths_fsd = {f.split('_')[1] + '_' + f.split('_')[2]:
                          os.path.join(directory, f) for f in self.files_fsd}
        self.day_hours, self.hours_since_year_start = \
            self.extract_hours_by_day(self.files_2du)
        self.transform = transform
        self.valid_indices = self.calculate_valid_indices()

    def extract_hours_by_day(self, strings):
        day_to_hours = {}
        for s in strings:
            parts = s.split('_')
            day, hour = parts[1], parts[2]
            if day not in day_to_hours:
                day_to_hours[day] = []
            day_to_hours[day].append(hour)
        day_hours = sorted((day, hour)
                           for day, hours in day_to_hours.items()
                           for hour in hours)
        hours_since_start = {f'{day}_{hour}':
                             24 * int(day) + int(hour)
                             for day, hours in day_to_hours.items()
                             for hour in hours}
        #  print('day_hours', day_hours)
        #  print('\nhours_since_start',  hours_since_start)
        return day_hours, hours_since_start

    def calculate_valid_indices(self):
        valid_indices = []
        #  print(f" in calculate valid index func\n")

        for i in range(len(self.day_hours) - self.D + 1):

            #  print(f"for loop i: {i}\n")

            start_day, start_hour = self.day_hours[i]
            #  print(f'start day and hour, {start_day} { start_hour}')

            start_hour_index = self.hours_since_year_start[
                f'{start_day}_{start_hour}']
            #  print(f'start hour index, {start_hour_index}')

            expected_end_hour_index = start_hour_index + (self.D-1)*self.skip
            # print(f'expected end hour index, {expected_end_hour_index}')
            expected_end_hour_index = start_hour_index + (self.D-1)*self.skip
            # print(f'expected end hour index, {expected_end_hour_index}')

            end_day, end_hour = self.day_hours[i + self.D - 1]
            # print(f'expected end day and hour {end_day}_{end_hour}\n')

            # print(f'expected end day and hour {end_day}_{end_hour}\n')

            if (self.hours_since_year_start.get(
                    f'{end_day}_{end_hour}', -1
                    ) == expected_end_hour_index):
                #  print('\n primeiro if')

                # To make sure we dont have diferent hours from diferent days
                if (int(end_day) == int(start_day)) or (self.skip % 24 == 0):
                    # print('\n segundo')
                if (int(end_day) == int(start_day)) or (self.skip % 24 == 0):
                    # print('\n segundo')
                    valid_indices.append(i)
        return valid_indices

    def __len__(self):
        return len(self.valid_indices)

    def __getitem__(self, idx, subwindow=None):
        if subwindow is None:
            subwindow = self.subwindow
        # print("Main __getitem__:\n")
        # print("Main __getitem__:\n")
        sequence_data = []
        # print('idx: ',idx)
        # print('idx: ',idx)
        actual_idx = self.valid_indices[idx]

        for offset in range(self.D):
            day, hour = self.day_hours[actual_idx + offset]
            filepath_2du = self.paths_2du[f'{day}_{hour}']
            filepath_fsd = self.paths_fsd[f'{day}_{hour}']
            with (netCDF4.Dataset(filepath_2du, "r") as nc_dataset_2du,
                  netCDF4.Dataset(filepath_fsd, "r") as nc_dataset_fsd):
                latitudes = nc_dataset_2du.variables['Latitude'][:]
                longitudes = nc_dataset_2du.variables['Longitude'][:]
                lat_idx, lon_idx = self.get_indices_from_proportion(
                    latitudes, longitudes, subwindow)

                u_velocity = nc_dataset_2du.variables['u_velocity'][
                    0, 0, lat_idx[0]:lat_idx[1], lon_idx[0]:lon_idx[1]]
                v_velocity = nc_dataset_2du.variables['v_velocity'][
                    0, 0, lat_idx[0]:lat_idx[1], lon_idx[0]:lon_idx[1]]
                ssh = nc_dataset_fsd.variables['ssh'][
                    0, lat_idx[0]:lat_idx[1], lon_idx[0]:lon_idx[1]]
                mask = np.ma.getmask(u_velocity)
                if len(mask.shape) == 0:
                    mask = np.zeros_like(u_velocity, dtype=bool)
                sequence_data.append((u_velocity, v_velocity, ssh, mask))

        tensors = [self.prepare_tensors(*data) for data in sequence_data]

        # Make tensor contiguous in the first dimension
        tensors = list(zip(*tensors))
        tensors = [torch.stack(t) for t in tensors]

        if self.transform:
            tensors = [self.transform(t) for t in tensors]
        return tensors, (day, hour)

    def get_indices_from_proportion(self, latitudes, longitudes, subwindow):
        if subwindow:
            lat_range = [int(subwindow[0][0] * len(latitudes)),
                         int(subwindow[0][1] * len(latitudes))]
            lon_range = [int(subwindow[1][0] * len(longitudes)),
                         int(subwindow[1][1] * len(longitudes))]
            return lat_range, lon_range
        return [0, len(latitudes)], [0, len(longitudes)]

    def prepare_tensors(self, u_velocity, v_velocity, ssh, mask):
        u_tensor = torch.tensor(u_velocity.filled(0.0), dtype=torch.float32)
        v_tensor = torch.tensor(v_velocity.filled(0.0), dtype=torch.float32)
        ssh_tensor = torch.tensor(ssh.filled(0.0), dtype=torch.float32)
        combined_tensor = torch.stack([u_tensor, v_tensor, ssh_tensor])
        mask_tensor = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)

        # Remove any possible nans, converting to 0.0
        combined_tensor = torch.nan_to_num(combined_tensor, nan=0.0)
        mask_tensor = torch.nan_to_num(mask_tensor, nan=1.0)

        return mask_tensor, combined_tensor


class ContiguousCurrentsDatasetAutoregressive(ContiguousCurrentsDataset):


    def __getitem__(self, idx, subwindow=None):
        tensors, (day, hour) = super().__getitem__(idx, subwindow)
        x = tensors[1][-1]
        y = tensors[1][0:-1]
        y = y.reshape(y.size(1), y.size(0), y.size(-2), y.size(-1))
        y = y.reshape(-1, y.size(-2), y.size(-1))
        mask = tensors[0][-1]
        return x, y, mask
        return x, y, mask


class MeanEncoder(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x, y):
        return self.decode(self.encode(x, y), y)

    def encode(self, x, y):

        return x - y[-3:, :, :]

    def decode(self, z, y):
        return z + y[-3:, :, :]





def train():
    transform = transforms.Compose([transforms.RandomCrop((128, 128))])
    dataset = ContiguousCurrentsDatasetAutoregressive(RESULTS2023PATH,
                                                      subwindow=[[0.0, 0.5],
                                                                 [0.5, 1.0]],
                                                      transform=transform,
                                                      D=3,
                                                      skip=24
                                                      )
    # x, y, mask, day = dataset[2]

                                                      transform=transform,
                                                      D=3,
                                                      skip=24
                                                      )
    # x, y, mask, day = dataset[2]

    def split_dataset_from_proportions(dataset, proportions):
        lengths = [int(p * len(dataset)) for p in proportions]
        lengths[-1] = len(dataset) - sum(lengths[:-1])
        return torch.utils.data.random_split(dataset, lengths)

    train_dataset, val_dataset = split_dataset_from_proportions(
        dataset, [0.8, 0.2])

    batch_size = 32
    train_dataloader = torch.utils.data.DataLoader(train_dataset,
                                                   batch_size=batch_size,
                                                   shuffle=True)
    val_dataloader = torch.utils.data.DataLoader(val_dataset,
                                                 batch_size=batch_size)
    encoder = MeanEncoder()
    model = poregen.models.PUNetBCond(64,
                                      channels=3,
                                      conditional_channels=6
                                      )
                                      conditional_channels=6
                                      )
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    module = poregen.models.KarrasModule(model=model,
                                         config=moduleconfig,
                                         conditional=True,
                                         masked=True,
                                         autoencoder=encoder,
                                         autoencoder_conditional=True)
    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH+"\\ocean-poorgencast-20240604",
        dirpath=MODELSPATH/"ocean-poorgencast-20240604-cond2d",
        filename='sample-{epoch:02d}-{valid_loss:.8f}',
        save_top_k=5,
        mode='min',
    )

    trainer = lightning.Trainer(max_epochs=300,
                                gradient_clip_val=0.5,
                                callbacks=[checkpoint_callback])
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    train()

================
File: training/training-script-20240527-karras-edm-punetb-a100.py
================
import pathlib
import argparse

import torch
import lightning
from lightning.pytorch.tuner.tuning import Tuner
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 1e-4,
                 num_epochs: int = 200,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
        )

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=255)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=255)
    
    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                # devices=1,
                                strategy="ddp",
                                fast_dev_run=False)
    
    # find hyperparameters
    # tuner = Tuner(trainer)
    module.lr = config.learning_rate
    # tuner.lr_find(module)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=module.lr)
    
    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 1
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))
    dataloader_size = len(train_dataloader)

    torch.set_float32_matmul_precision('high')

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--imagesize', type=int, default=192)
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    model = poregen.models.PUNetBUncond(64, dropout=0.2)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
        moduleconfig.loss_metric = "huber"
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    module = poregen.models.KarrasModule(model, moduleconfig)

    # checkpoint = MAINPATH/'savedmodels/experimental/[pore]-[2024-05-27]-[bps]-[bereapunetb-mse2]/sample-epoch=49-valid_loss=0.084942.ckpt'

    # module = poregen.models.KarrasModule.load_from_checkpoint(
    #     checkpoint,
    #     model=model,
    #     config=moduleconfig
    # )

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize)
    main(config, module)

================
File: training/training-script-20240606-porrgencast-multy-models.py
================
import pathlib
import os

import torch
import torchvision.transforms.v2 as transforms
import lightning
import numpy as np
import lightning.pytorch.callbacks as callbacks
import netCDF4

import poregen.models
from poregen.dataloaders.oceandataloader import *

# CURRENTPATH = pathlib.Path(__file__).parent.absolute()
"""MAINPATH = 'C:\\Users\\ntana\\poregen\\poregen'

RESULTS2023PATH = 'C:\\Users\\ntana\\Project_LABMA\\OceanData\\resultados_2023'

DATAPATH = MAINPATH + "\\saveddata"
# RESULTS2023PATH = DATAPATH / "raw" / "currents_southeast_2023"
MODELSPATH = MAINPATH + "\\savedmodels\\experimental"
"""

CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH / "saveddata"
RESULTS2023PATH = DATAPATH / "raw" / "currents_southeast_2023"
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class MeanEncoder(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x, y):
        return self.decode(self.encode(x, y), y)

    def encode(self, x, y):

        return x - y['y'][:, -3:, :, :]

    def decode(self, z, y):
        return z + y['y'][:, -3:, :, :]


class MeanEncoder_sshonly(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x, y):
        return self.decode(self.encode(x, y), y)

    def encode(self, x, y):

        return x - y[:, -1:, :, :]

    def decode(self, z, y):
        return z + y[:, -1:, :, :]


def train():

    train_config = {'skip': [24, 12, 6], 'D': [4, 7, 13]}
    sshonly_config = [False]

    transform = transforms.Compose([transforms.RandomCrop((128, 128))])
    covariables = [[True, True]]
    for r_latlon, r_bat in covariables:
        print(r_latlon, r_bat)
        for ssh_only in sshonly_config:
            if ssh_only:
                encoder = MeanEncoder_sshonly()
            else:
                encoder = MeanEncoder()

            for skip, D in zip(train_config['skip'], train_config['D']):
                dataset = ContiguousCurrentsDatasetAutoregressive(
                                                            RESULTS2023PATH,
                                                            subwindow=[[[0.5, 1],
                                                                        [0.5, 1]],

                                                                    [[0.0, 0.5],
                                                                        [0, 0.5]]],
                                                            transform=transform,
                                                            D=D,
                                                            skip=skip,
                                                            ssh_only=ssh_only,
                                                            r_day=False,
                                                            r_latlon=r_latlon,
                                                            r_bat=r_bat)
                # x, y, mask = dataset[2]
                # print(y['latlon'].shape)

                train_dataset, val_dataset = split_dataset_from_proportions(
                    dataset, [0.8, 0.2])

                batch_size = 32
                train_dataloader = torch.utils.data.DataLoader(
                                                            train_dataset,
                                                            batch_size=batch_size,
                                                            shuffle=True)
                val_dataloader = torch.utils.data.DataLoader(val_dataset,
                                                            batch_size=batch_size)
                if ssh_only:
                    channels = 1
                else:
                    channels = 3

                torch.cuda.empty_cache()

                model = poregen.models.OUNetCond(64,
                                                channels=channels,
                                                conditional_channels=(D-1)*channels,
                                                date_embed_boll=False,
                                                geo_embed_boll=True,
                                                batimetry=True
                                                )
                moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
                module = poregen.models.KarrasModule(model=model,
                                                    config=moduleconfig,
                                                    conditional=True,
                                                    masked=True,
                                                    autoencoder=encoder,
                                                    autoencoder_conditional=True)
                checkpoint_callback = callbacks.ModelCheckpoint(
                    monitor='valid_loss',
                    dirpath=MODELSPATH/f"[ocean]-[poorgencast]-[20240716]-[D={D}]-[Skip={skip}]-[ssh_only={ssh_only}]-[r_lat = {r_latlon}]-[r_bat = {r_bat}]",
                    filename='sample-{epoch:02d}-{valid_loss:.8f}',
                    save_top_k=5,
                    mode='min',
                )
                lr_monitor = callbacks.LearningRateMonitor(logging_interval='step')

                early_stop_callback = callbacks.EarlyStopping(
                                                    monitor='valid_loss',
                                                    min_delta=0.00,
                                                    patience=500,
                                                    verbose=True,
                                                    mode='min')

                trainer = lightning.Trainer(max_epochs=1000,
                                            gradient_clip_val=0.5,
                                            callbacks=[checkpoint_callback,
                                                    lr_monitor,
                                                    early_stop_callback],
                                            fast_dev_run=False
                                            )

                trainer.fit(model=module,
                            train_dataloaders=train_dataloader,
                            val_dataloaders=val_dataloader
                            )

if __name__ == "__main__":
    train()

================
File: training/training-script-20240610-karras-edm-punetc.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
        )

    # find hyperparameters
    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accumulate_grad_batches=4)
    # tuner = Tuner(trainer)
    # module.lr = config.learning_rate
    # tuner.lr_find(module)
    # batch_size = tuner.scale_batch_size(module)
    batch_size = config.batch_size

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--imagesize', type=int, default=192)
    datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    savefolderstr = '[pore]-[2024-06-10]-[dfn]-[bereapunetc]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    # savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    model = poregen.models.PUNetCUncond(32, dropout=0.2)
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    module = poregen.models.KarrasModule(model, moduleconfig)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    num_epochs=50)
    main(config, module)

================
File: training/training-script-20240612-karras-edm-tpc.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers
import porespy

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def extract_two_point_correlation(slice):
    data = porespy.metrics.two_point_correlation((1 - slice[0]).numpy())
    dist = torch.tensor(data.distance, dtype=torch.float)
    prob = torch.tensor(data.probability_scaled, dtype=torch.float)
    return {'dist': dist, 'prob': prob}


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size,
        feature_extractor=extract_two_point_correlation)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size,
        feature_extractor=extract_two_point_correlation)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
        )

    # find hyperparameters
    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback])
    # tuner = Tuner(trainer)
    # module.lr = config.learning_rate
    # tuner.lr_find(module)
    # batch_size = tuner.scale_batch_size(module)
    batch_size = config.batch_size

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--imagesize', type=int, default=192)
    datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    savefolderstr = '[pore]-[2024-06-12]-[dfn]-[bereapunetpc]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    # savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    model_channels = 64
    tpc_embedder = poregen.models.TwoPointCorrelationEmbedder(model_channels)
    tpc_transformer = poregen.models.TwoPointCorrelationTransformer(
        tpc_embedder
    )
    modelconfig = poregen.models.PUNetGConfig(model_channels=model_channels,
                                              dropout=0.2)
    model = poregen.models.PUNetG(modelconfig, tpc_transformer)

    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()

    module = poregen.models.KarrasModule(model,
                                         moduleconfig,
                                         conditional=True)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    num_epochs=100)
    main(config, module)

================
File: training/training-script-20240617-karras-edm-tpc-3.py
================
import pathlib
import argparse

import torch
import numpy as np
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers
import porespy

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-4,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def extract_two_point_correlation_from_slice(voxel):
    voxel = voxel[0]
    ind = np.random.randint(0, voxel.shape[0])
    slice = voxel[ind, :, :]
    data = porespy.metrics.two_point_correlation((1 - slice).numpy())
    dist = torch.tensor(data.distance, dtype=torch.float)
    prob = torch.tensor(data.probability_scaled, dtype=torch.float)
    prob = torch.nan_to_num(prob)

    return {'dist': dist, 'prob': prob}


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        subslice=[image_size, image_size, image_size],
        feature_extractor=extract_two_point_correlation_from_slice)
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        subslice=[image_size, image_size, image_size],
        feature_extractor=extract_two_point_correlation_from_slice)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
        )

    # find hyperparameters
    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                strategy="ddp")
    # tuner = Tuner(trainer)
    # module.lr = config.learning_rate
    # tuner.lr_find(module)
    # batch_size = tuner.scale_batch_size(module)
    batch_size = config.batch_size

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=50,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--imagesize', type=int, default=64)
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    savefolderstr = '[pore]-[2024-06-17]-[dfn]-[bereapunetpc]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    # savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-05-20]-[bps]-[ldmvae3d-l2]/sample-epoch=29-val/rec_loss=0.006102.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig()
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(resolution=64)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    model_channels = 64
    tpc_embedder = poregen.models.TwoPointCorrelationEmbedder(model_channels)
    tpc_transformer = poregen.models.TwoPointCorrelationTransformer(
        tpc_embedder
    )
    modelconfig = poregen.models.PUNetGConfig(input_channels=4,
                                              output_channels=4,
                                              model_channels=model_channels,
                                              dropout=0.2,
                                              dimension=3)
    model = poregen.models.PUNetG(modelconfig, tpc_transformer)

    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()

    module = poregen.models.KarrasModule(model,
                                         moduleconfig,
                                         conditional=True,
                                         autoencoder=vae_module)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    num_epochs=200)
    main(config, module)

================
File: training/training-script-20240619-karras-edm.py
================
import pathlib
import argparse

import torch
import numpy as np
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers
import porespy

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-4,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        subslice=[image_size, image_size, image_size])
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        subslice=[image_size, image_size, image_size])

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
        )

    # find hyperparameters
    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                strategy="ddp")
    # tuner = Tuner(trainer)
    # module.lr = config.learning_rate
    # tuner.lr_find(module)
    # batch_size = tuner.scale_batch_size(module)
    batch_size = config.batch_size

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=23)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=23)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=50,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--imagesize', type=int, default=64)
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    # savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-05-20]-[bps]-[ldmvae3d-l2]/sample-epoch=29-val/rec_loss=0.006102.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig()
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(resolution=64)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    model_channels = 64
    modelconfig = poregen.models.PUNetGConfig(input_channels=4,
                                              output_channels=4,
                                              model_channels=model_channels,
                                              dropout=0.2,
                                              dimension=3)
    model = poregen.models.PUNetG(modelconfig)

    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()

    diffcheckpoint = MAINPATH/'savedmodels/experimental/[pore]-[2024-06-19]-[bps]-[bereapunetg-3d-ldm]/sample-epoch=15-valid_loss=1.222414.ckpt'

    module = poregen.models.KarrasModule.load_from_checkpoint(
        diffcheckpoint,
        model=model,
        config=moduleconfig,
        autoencoder=vae_module)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    num_epochs=50)
    main(config, module)

================
File: training/training-script-20240620-karras-edm-g.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel 
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accumulate_grad_batches=1)
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--image-size', type=int, default=192)
    # datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = 'script-20240123'
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    savefolderstr = '[pore]-[2024-06-20]-[dfn]-[remaking-edm-g]'
    args = parser.parse_args()
    kindofdata = args.kindofdata
    imagesize = args.image_size

    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=64,
                                              dropout=0.2,
                                              dimension=2,
                                              number_resnet_attn_block=0,
                                              number_resnet_before_attn_block=3,
                                              number_resnet_after_attn_block=3)
    model = poregen.models.PUNetG(modelconfig)

    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    module = poregen.models.KarrasModule(model, moduleconfig)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    batch_size=16,
                    num_epochs=50)
    main(config, module)

================
File: training/training-script-20240620-karras-edm-g2.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel 
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSlicesDataset(
        train_voxel,
        transform=transform,
        image_size=image_size)
    val_dataset = poregen.data.VoxelToSlicesDataset(
        valid_voxel,
        transform=transform,
        image_size=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=4)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=nsteps//10,
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accumulate_grad_batches=4)
    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--image-size', type=int, default=192)
    # datastr = 'berea/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = 'script-20240123'
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    savefolderstr = '[pore]-[2024-06-20]-[dfn]-[remaking-edm-g2]'
    args = parser.parse_args()
    kindofdata = args.kindofdata
    imagesize = args.image_size

    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=64,
                                              dropout=0.2,
                                              dimension=2,
                                              number_resnet_attn_block=2,
                                              number_resnet_before_attn_block=2,
                                              number_resnet_after_attn_block=2)
    model = poregen.models.PUNetG(modelconfig)

    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    module = poregen.models.KarrasModule(model, moduleconfig)
    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    batch_size=4,
                    num_epochs=50)
    main(config, module)

================
File: training/training-script-20240623-toy-chessboard.py
================
import pathlib
import argparse

import torch
import numpy as np
import numpy.random as rd
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 100,
                 learning_rate: float = 2*1e-4,
                 num_epochs: int = 200,
                 lr_scheduler: None | str = None):
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


class CheckerboardDataset(torch.utils.data.Dataset):
    def __init__(self,
                 imagesize: int = [64, 64],
                 boardsize: int = [4, 4],
                 dataset_size: int = 100000):
        self.imagesize = imagesize
        self.boardsize = boardsize
        if (imagesize[0] % boardsize[0] == 0) and (imagesize[0] % boardsize[0] == 0):
            self.rectangle_size = [imagesize[0]/boardsize[0],
                                   imagesize[1]/boardsize[1]]
        else:
            raise ValueError(
                f'imagesize should be a multiple of boardsize: {imagesize} {boardsize}')
        self.dataset_size = dataset_size

    def __len__(self):
        return self.dataset_size

    def __getitem__(self, idx):
        idxs = np.stack([rd.randint(32), rd.randint(64)])
        rect = self.rectangle_size
        region = idxs[1]//rect[1]
        if region % 2 == 0:
            idxs[0] = 2*(idxs[0]//rect[0]) * rect[0] + idxs[0] % rect[0]
        else:
            idxs[0] = (2*(idxs[0]//rect[0])+1) * rect[0] + idxs[0] % rect[0]
        return idxs

    def sample(self, nsamples):
        idxs = np.stack([rd.randint(32, size=nsamples),
                         rd.randint(64, size=nsamples)])
        coords = idxs
        for i in range(nsamples):
            rect = self.rectangle_size
            region = idxs[1, i]//rect[1]
            if region % 2 == 0:
                coords[0, i] = (2*(idxs[0, i]//rect[0]) * rect[0]
                                + idxs[0, i] % rect[0])
            else:
                coords[0, i] = ((2*(idxs[0, i]//rect[0])+1) * rect[0]
                                + idxs[0, i] % rect[0])
        return coords.T


def main(config, module):

    nsamples = 100000
    dataset = CheckerboardDataset(dataset_size=nsamples)
    samples = dataset.sample(nsamples=nsamples)

    # data for training
    batch_size = config.batch_size
    train_size = int(nsamples*0.5)
    test_size = nsamples - train_size
    num_workers = 0
    # normalize data
    samples = samples - (32, 32)
    samples = samples / 32
    samples = torch.tensor(samples, dtype=torch.float32)

    train_dataset, val_dataset = torch.utils.data.random_split(
        samples, [train_size, test_size])
    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True,
        num_workers=num_workers)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False,
        num_workers=num_workers)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
        )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=5*len(train_dataloader),
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None

    torch.set_float32_matmul_precision('medium')

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                fast_dev_run=False,
                                gradient_clip_val=2
                                )

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    args = parser.parse_args()
    savefolderstr = args.savefolderstr

    model = poregen.models.MLPUncond(2, [1000, 1000, 1000, 1000])
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    module = poregen.models.KarrasModule(model,
                                         moduleconfig)

    config = Config(savefolderstr,
                    learning_rate=2e-3,
                    batch_size=50,
                    num_epochs=50)
    main(config, module)

================
File: training/training-script-20240624-edm-a100-tpc.py
================
import pathlib
import argparse

import torch
import numpy as np
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers
import porespy

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 192,
                 learning_rate: float = 2*1e-4,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def extract_two_point_correlation_from_slice(voxel):
    voxel = voxel[0]
    ind = np.random.randint(0, voxel.shape[0])
    slice = voxel[ind, :, :]
    data = porespy.metrics.two_point_correlation((1 - slice).numpy())
    dist = torch.tensor(data.distance, dtype=torch.float)
    prob = torch.tensor(data.probability_scaled, dtype=torch.float)
    prob = torch.nan_to_num(prob)

    return {'dist': dist, 'prob': prob}


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    image_size = config.image_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        subslice=[image_size, image_size, image_size],
        feature_extractor=extract_two_point_correlation_from_slice)
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        subslice=[image_size, image_size, image_size],
        feature_extractor=extract_two_point_correlation_from_slice)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
        )

    batch_size = config.batch_size

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=23)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=23)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    if config.lr_scheduler == 'cosine':
        nsteps = len(train_dataloader)*config.num_epochs
        module.lr_scheduler = transformers.get_cosine_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=5*len(train_dataloader),
            num_training_steps=nsteps)
    elif config.lr_scheduler == 'constant':
        module.lr_scheduler = transformers.get_constant_schedule_with_warmup(
            module.optimizer,
            num_warmup_steps=0,
            last_epoch=-1)
    elif config.lr_scheduler is None:
        module.lr_scheduler = None
    
    torch.set_float32_matmul_precision('medium')

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                strategy="ddp",
                                fast_dev_run=False,
                                gradient_clip_val=0.5
                                )

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    # parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--imagesize', type=int, default=64)
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    # savefolderstr = args.savefolderstr
    savefolderstr = '[pore]-[2024-06-24]-[dfn]-[latent-test-v100]'
    # savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    # checkpoint_path=(MAINPATH/'savedmodels/experimental/[pore]-[2024-06-06]-[bps]-[ldmvae3d-64]/sample-epoch=130-val/rec_loss=0.008684.ckpt')

    # lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(
    #     kl_weight=1.0)
    # ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
    #     ch=32,
    #     ch_mult=(1,2,2),
    #     resolution=imagesize,
    #     dropout=0.1)
    
    checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-05-20]-[bps]-[ldmvae3d-l2]/sample-epoch=29-val/rec_loss=0.006102.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig()
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(resolution=imagesize)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    model_channels = 64
    tpc_embedder = poregen.models.TwoPointCorrelationEmbedder(model_channels)
    tpc_transformer = poregen.models.TwoPointCorrelationTransformer(
        tpc_embedder
    )

    modelconfig = poregen.models.PUNetGConfig(input_channels=4,
                                              output_channels=4,
                                              number_resnet_attn_block=0,
                                              number_resnet_after_attn_block=3,
                                              number_resnet_before_attn_block=3,
                                              model_channels=model_channels,
                                              dropout=0.2,
                                              dimension=3)
    model = poregen.models.PUNetG(modelconfig, tpc_transformer)

    moduleconfig = poregen.models.KarrasModuleConfig.from_edm()

    # diffcheckpoint = MAINPATH/'savedmodels/experimental/[pore]-[2024-06-19]-[bps]-[bereapunetg-3d-ldm]/sample-epoch=15-valid_loss=1.222414.ckpt'

    # module = poregen.models.KarrasModule.load_from_checkpoint(
    #     diffcheckpoint,
    #     model=model,
    #     config=moduleconfig,
    #     autoencoder=vae_module)

    module = poregen.models.KarrasModule(model,
                                         moduleconfig,
                                         conditional=True,
                                         autoencoder=vae_module)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    learning_rate=4e-4,
                    batch_size=32,       # It is on V100
                    num_epochs=200)
    main(config, module)

================
File: training/training-script-20240626-testing-scaling-laws.py
================
import pathlib

import numpy as np
import torch

import poregen.data
import poregen.models
import poregen.trainers


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


voxel_path = (
    MAINPATH /
    'saveddata/raw/eleven_sandstones/BanderaBrown_2d25um_binary.raw'
)

savepath = (
    MAINPATH /
    'savedmodels/experimental/[pore]-[2024-06-26]-[testnewtrainer2dscaling]'
)


def run(model_channels):
    trainerconfig = poregen.trainers.UnconditionalBinaryVoxelTrainerConfig1(
        voxel_path,
        savepath,
        image_size=32,
        batch_size=16,
        voxel_downscale_factor=4,
        dimension=2,
        training_dataset_size=34560//4,
        validation_dataset_size=3840,
        num_epochs=1,
        num_lr_cycles=1,
        learning_scheduler='constant'
    )
    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=model_channels,
                                              dropout=0.0,
                                              number_resnet_attn_block=0,
                                              dimension=2)
    model = poregen.models.PUNetG(modelconfig)
    _ = poregen.trainers.train_unconditional_single_binary_voxel_1(
        model=model,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="auto"
    )


for model_channels in [int(2**i) for i in np.linspace(2, 6, 10)]:
    run(model_channels)
    torch.cuda.empty_cache()

================
File: training/training-script-20240628-porosity-control.py
================
import os
import pathlib
import argparse

import poregen.data
import poregen.models
import poregen.trainers
import poregen.features


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-channels', type=int, default=16)
    args = parser.parse_args()
    model_channels = args.model_channels


    sandstones = sorted([
        b for b in os.listdir(MAINPATH/'saveddata/raw/eleven_sandstones')
        if 'binary' in b])[-3:]
    voxel_paths = [MAINPATH/'saveddata/raw/eleven_sandstones'/sandstone for 
                   sandstone in sandstones]
    voxel_paths = sorted(voxel_paths)[:8]
    savepath = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-06-27]-[test-control]')
    trainerconfig = poregen.trainers.BinaryVoxelTrainerConfig1(
        voxel_paths,
        savepath,
        image_size=64,
        batch_size=2,
        voxel_downscale_factor=4,
        dimension=3,
        training_dataset_size=34560,
        validation_dataset_size=3840,
        num_epochs=50,
        num_lr_cycles=1,
        learning_scheduler='constant',
        feature_extractor=['extract_porosity',
                           'extract_porosimetry_from_voxel_slice'])
    porosity_embedder = poregen.models.PorosityEmbedder(model_channels)

    psd_embedder = poregen.models.PoreSizeDistEmbedder(model_channels)
    psd_transformer = poregen.models.PoreSizeDistTransformer(
        psd_embedder
    )

    embedder = poregen.models.CompositeEmbedder(
        [porosity_embedder, psd_embedder])
    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=model_channels,
                                              dropout=0.2,
                                              cond_dropout=0.2,
                                              number_resnet_attn_block=0,
                                              number_resnet_before_attn_block=3,
                                              number_resnet_after_attn_block=3,
                                              dimension=3)
    model = poregen.models.PUNetG(modelconfig, porosity_embedder)
    _ = poregen.trainers.train_binary_voxel_1(
        model=model,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="ddp",
        conditional=True
    )

================
File: training/training-script-20240702-porosity-control-single-latent.py
================
import os
import pathlib
import argparse

import poregen.data
import poregen.models
import poregen.trainers
import poregen.features


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-channels', type=int, default=16)
    args = parser.parse_args()
    model_channels = args.model_channels

    # checkpoint_path_vae = (MAINPATH/
        # 'savedmodels/experimental/[pore]-[2024-05-20]-[bps]-[ldmvae3d-l2]/sample-epoch=29-val/rec_loss=0.006102.ckpt')

    # lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig()
    # ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(resolution=64)

    # vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        # checkpoint_path_vae, ddconfig=ddconfig, lossconfig=lossconfig
        # )
    # vae_module.eval();

    # vae_module = poregen.models.load_autoencoder("tiny1")
    # vae_module.eval()

    checkpoint_path=(MAINPATH/'savedmodels/experimental/[pore]-[2024-06-06]-[bps]-[ldmvae3d-64]/sample-epoch=130-val/rec_loss=0.008684.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(
        kl_weight=1.0)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        ch=32,
        ch_mult=(1,2,2),
        resolution=64,
        dropout=0.1)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    # sandstones = sorted([
        # b for b in os.listdir(MAINPATH/'saveddata/raw/eleven_sandstones')
        # if 'binary' in b])[-3:]
    # voxel_paths = [MAINPATH/'saveddata/raw/eleven_sandstones'/sandstone for 
                #    sandstone in sandstones]
    # voxel_paths = sorted(voxel_paths)[:8]

    voxel_paths = MAINPATH/'saveddata/raw/eleven_sandstones/BanderaBrown_2d25um_binary.raw'

    savepath = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-07-03]-[controlled-latent-test]')
    feature_extractor = 'extract_porosity'
    trainerconfig = poregen.trainers.BinaryVoxelTrainerConfig1(
        voxel_paths,
        savepath,
        image_size=64,
        batch_size=4,
        voxel_downscale_factor=2,
        dimension=3,
        training_dataset_size=34560,
        validation_dataset_size=3840,
        num_epochs=20,
        num_lr_cycles=1,
        learning_scheduler='constant',
        feature_extractor=feature_extractor,
        psplit=0.8,
        center=False,
        invert=False,
    )
    porosity_embedder = poregen.models.PorosityEmbedder(model_channels)

    psd_embedder = poregen.models.PoreSizeDistEmbedder(model_channels)
    psd_transformer = poregen.models.PoreSizeDistTransformer(
        psd_embedder
    )

    embedder = poregen.models.CompositeEmbedder(
        [porosity_embedder, psd_transformer])
    modelconfig = poregen.models.PUNetGConfig(input_channels=4,
                                              output_channels=4,
                                              model_channels=model_channels,
                                              dropout=0.2,
                                              cond_dropout=0.2,
                                              number_resnet_attn_block=0,
                                              number_resnet_before_attn_block=2,
                                              number_resnet_after_attn_block=2,
                                              dimension=3,
                                              convolution_type='circular')
    model = poregen.models.PUNetG(modelconfig, porosity_embedder)
    _ = poregen.trainers.train_binary_voxel_1(
        model=model,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="ddp",
        conditional=True,
        autoencoder=vae_module
    )

================
File: training/training-script-20240702-porosity-control-single.py
================
import os
import pathlib
import argparse

import poregen.data
import poregen.models
import poregen.trainers
import poregen.features


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-channels', type=int, default=16)
    args = parser.parse_args()
    model_channels = args.model_channels


    # sandstones = sorted([
        # b for b in os.listdir(MAINPATH/'saveddata/raw/eleven_sandstones')
        # if 'binary' in b])[-3:]
    # voxel_paths = [MAINPATH/'saveddata/raw/eleven_sandstones'/sandstone for 
                #    sandstone in sandstones]
    # voxel_paths = sorted(voxel_paths)[:8]

    voxel_paths = MAINPATH/'saveddata/raw/eleven_sandstones/BanderaBrown_2d25um_binary.raw'

    savepath = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-07-03]-[controlled-nocond]')
    feature_extractor = 'extract_porosity'
    trainerconfig = poregen.trainers.BinaryVoxelTrainerConfig1(
        voxel_paths,
        savepath,
        image_size=64,
        batch_size=4,
        voxel_downscale_factor=2,
        dimension=3,
        training_dataset_size=34560,
        validation_dataset_size=3840,
        num_epochs=20,
        num_lr_cycles=1,
        learning_scheduler='constant',
        feature_extractor=feature_extractor,
        psplit=0.8
    )
    porosity_embedder = poregen.models.PorosityEmbedder(model_channels)

    psd_embedder = poregen.models.PoreSizeDistEmbedder(model_channels)
    psd_transformer = poregen.models.PoreSizeDistTransformer(
        psd_embedder
    )

    embedder = poregen.models.CompositeEmbedder(
        [porosity_embedder, psd_transformer])
    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=model_channels,
                                              dropout=0.2,
                                              cond_dropout=0.2,
                                              number_resnet_attn_block=0,
                                              number_resnet_before_attn_block=2,
                                              number_resnet_after_attn_block=2,
                                              dimension=3,
                                              convolution_type='circular')
    model = poregen.models.PUNetG(modelconfig, porosity_embedder)
    _ = poregen.trainers.train_binary_voxel_1(
        model=model,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="ddp",
        conditional=True
    )

================
File: training/training-script-20240703-nocond-latent.py
================
import os
import pathlib
import argparse

import poregen.data
import poregen.models
import poregen.trainers
import poregen.features


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-channels', type=int, default=16)
    args = parser.parse_args()
    model_channels = args.model_channels


    # sandstones = sorted([
        # b for b in os.listdir(MAINPATH/'saveddata/raw/eleven_sandstones')
        # if 'binary' in b])[-3:]
    # voxel_paths = [MAINPATH/'saveddata/raw/eleven_sandstones'/sandstone for 
                #    sandstone in sandstones]
    # voxel_paths = sorted(voxel_paths)[:8]
    checkpoint_path=(MAINPATH/'savedmodels/experimental/[pore]-[2024-06-06]-[bps]-[ldmvae3d-64]/sample-epoch=130-val/rec_loss=0.008684.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(
        kl_weight=1.0)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        ch=32,
        ch_mult=(1,2,2),
        resolution=64,
        dropout=0.1)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    voxel_paths = MAINPATH/'saveddata/raw/eleven_sandstones/BanderaBrown_2d25um_binary.raw'

    savepath = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-07-03]-[controlled-nocond]')
    trainerconfig = poregen.trainers.BinaryVoxelTrainerConfig1(
        voxel_paths,
        savepath,
        image_size=64,
        batch_size=4,
        voxel_downscale_factor=2,
        dimension=3,
        training_dataset_size=34560,
        validation_dataset_size=3840,
        num_epochs=20,
        num_lr_cycles=1,
        learning_scheduler='constant',
        psplit=0.8
    )

    modelconfig = poregen.models.PUNetGConfig(input_channels=4,
                                              output_channels=4,
                                              model_channels=model_channels,
                                              dropout=0.2,
                                              cond_dropout=0.2,
                                              number_resnet_attn_block=0,
                                              number_resnet_before_attn_block=2,
                                              number_resnet_after_attn_block=2,
                                              dimension=3,
                                              convolution_type='circular')
    model = poregen.models.PUNetG(modelconfig)
    _ = poregen.trainers.train_binary_voxel_1(
        model=model,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="ddp",
        conditional=False,
        autoencoder=vae_module
    )

================
File: training/training-script-20240703-nocond.py
================
import os
import pathlib
import argparse

import poregen.data
import poregen.models
import poregen.trainers
import poregen.features


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-channels', type=int, default=16)
    args = parser.parse_args()
    model_channels = args.model_channels


    # sandstones = sorted([
        # b for b in os.listdir(MAINPATH/'saveddata/raw/eleven_sandstones')
        # if 'binary' in b])[-3:]
    # voxel_paths = [MAINPATH/'saveddata/raw/eleven_sandstones'/sandstone for 
                #    sandstone in sandstones]
    # voxel_paths = sorted(voxel_paths)[:8]

    voxel_paths = MAINPATH/'saveddata/raw/eleven_sandstones/BanderaBrown_2d25um_binary.raw'

    savepath = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-07-03]-[controlled-nocond]')
    trainerconfig = poregen.trainers.BinaryVoxelTrainerConfig1(
        voxel_paths,
        savepath,
        image_size=64,
        batch_size=4,
        voxel_downscale_factor=2,
        dimension=3,
        training_dataset_size=34560,
        validation_dataset_size=3840,
        num_epochs=20,
        num_lr_cycles=1,
        learning_scheduler='constant',
        psplit=0.8
    )

    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=model_channels,
                                              dropout=0.2,
                                              cond_dropout=0.2,
                                              number_resnet_attn_block=0,
                                              number_resnet_before_attn_block=2,
                                              number_resnet_after_attn_block=2,
                                              dimension=3,
                                              convolution_type='circular')
    model = poregen.models.PUNetG(modelconfig)
    _ = poregen.trainers.train_binary_voxel_1(
        model=model,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="ddp",
        conditional=False
    )

================
File: training/training-script-20240704-nocond-norm.py
================
import os
import pathlib
import argparse

import poregen.data
import poregen.models
import poregen.trainers
import poregen.features


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-channels', type=int, default=16)
    parser.add_argument('--scheduler', type=str, default='constant')
    args = parser.parse_args()
    model_channels = args.model_channels
    scheduler = args.scheduler


    # sandstones = sorted([
        # b for b in os.listdir(MAINPATH/'saveddata/raw/eleven_sandstones')
        # if 'binary' in b])[-3:]
    # voxel_paths = [MAINPATH/'saveddata/raw/eleven_sandstones'/sandstone for 
                #    sandstone in sandstones]
    # voxel_paths = sorted(voxel_paths)[:8]

    voxel_paths = MAINPATH/'saveddata/raw/eleven_sandstones/BanderaBrown_2d25um_binary.raw'

    savepath = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-07-04]-[controlled-nocond-norm]')
    trainerconfig = poregen.trainers.BinaryVoxelTrainerConfig1(
        voxel_paths,
        savepath,
        image_size=64,
        batch_size=4,
        voxel_downscale_factor=2,
        dimension=3,
        training_dataset_size=34560,
        validation_dataset_size=3840,
        num_epochs=30,
        num_lr_cycles=2,
        learning_scheduler=scheduler,
        psplit=0.8,
        center=True,
        warmup_step_percentage=0.05,
        mean_learning_rate=4*1e-5
    )

    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=model_channels,
                                              dropout=0.0,
                                              cond_dropout=0.0,
                                              number_resnet_attn_block=2,
                                              number_resnet_before_attn_block=2,
                                              number_resnet_after_attn_block=2,
                                              dimension=3,
                                              convolution_type='default',
                                              channel_expansion=[2, 4, 8])
    model = poregen.models.PUNetG(modelconfig)
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm(sigma_data=0.5)
    _ = poregen.trainers.train_binary_voxel_1(
        model=model,
        moduleconfig=moduleconfig,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="ddp",
        conditional=False
    )

================
File: training/training-script-20240708-autoencoder_ldm3d-a100.py
================
import pathlib
import argparse

import torch
# import numpy as np
import lightning
from lightning.pytorch.tuner.tuning import Tuner
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models

torch.cuda.empty_cache()

CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 64,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # image_size = config.image_size
    batch_size = config.batch_size
    image_size = config.image_size

    transform = poregen.data.get_standard_binary_transforms()

    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=image_size)
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=255)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False, num_workers=255)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='val/rec_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{val/rec_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                strategy="ddp",
                                fast_dev_run=False,
                                gradient_clip_val=0.5)

    # tuner = Tuner(trainer)
    module.learning_rate = config.learning_rate
    # tuner.lr_find(module)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)

    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 5
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))

    torch.set_float32_matmul_precision('medium')

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


# class TemporaryModel(poregen.models.nets.MLPUncond):
#     def forward(self, x, t):
#         oldshape = list(x.shape)
#         newshape = np.prod(oldshape[1:])
#         x = super().forward(x.reshape(-1, newshape), t)
#         x = x.reshape(*oldshape)
#         return x


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=64)
    parser.add_argument('--sandstone', type=str, default='berea')
    parser.add_argument('--compression', type=str, default='8x')

    args = parser.parse_args()
    kindofdata = args.kindofdata
    # savefolderstr = '[pore]-[2024-05-14]-[bps]-[ldmvae3d]'
    savefolderstr = args.savefolderstr
    imagesize = args.image_size
    compression = args.compression

    sandstone = args.sandstone
    if sandstone=='berea':
        datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    elif sandstone=='banderabrown':
        datastr = 'eleven_sandstones/BanderaBrown_2d25um_binary.raw'
    elif sandstone=='estaillades':
        datastr = 'imperial_college/Estaillades_1000c_3p31136um.raw'
    else:
        raise ValueError(
            '-sandstone argument should be either berea, banderabrown or estaillades')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(kl_weight=1e-4)
    if compression=='8x':
            ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
            resolution=imagesize,
            has_mid_attn=False)
    elif compression=='16x':
        ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
            resolution=imagesize,
            has_mid_attn=False,
            ch_mult=[1, 2, 2, 4, 4])
    else:
        raise NotImplementedError('--compression should be either 8x or 16x')

    vae_model = poregen.models.nets.autoencoderldm3d.AutoencoderKL(ddconfig,
                                                                   lossconfig)
    # checkpoint = (MAINPATH/'savedmodels/experimental' /
    #               '[pore]-[2024-05-14]-[bps]-[ldmvae3d]' /
    #               'sample-epoch=09-val/rec_loss=0.020127.ckpt')

    # vae_model = (
    #     poregen.models.nets.autoencoderldm3d.AutoencoderKL
    #     .load_from_checkpoint(
    #         checkpoint, ddconfig=ddconfig, lossconfig=lossconfig
    #         )
    # )

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3,
                    batch_size=4,       # effective batch size: 8 x 4 = 32
                    num_epochs=150)

    main(config, vae_model)

================
File: training/training-script-20240710-test-different-nets-attn.py
================
import os
import pathlib
import argparse

import poregen.data
import poregen.models
import poregen.trainers
import poregen.features


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-channels', type=int, default=16)
    parser.add_argument('--scheduler', type=str, default='constant')

    parser.add_argument('--in-embedding',
                        default=False,
                        action=argparse.BooleanOptionalAction)
    parser.add_argument('--mp',
                        default=False,
                        action=argparse.BooleanOptionalAction)

    args = parser.parse_args()
    model_channels = args.model_channels
    scheduler = args.scheduler
    in_embeddings = args.in_embedding
    mp = args.mp

    # sandstones = sorted([
        # b for b in os.listdir(MAINPATH/'saveddata/raw/eleven_sandstones')
        # if 'binary' in b])[-3:]

    # voxel_paths = [MAINPATH/'saveddata/raw/eleven_sandstones'/sandstone for 
                #    sandstone in sandstones]
    # voxel_paths = sorted(voxel_paths)[:8]

    voxel_paths = MAINPATH/'saveddata/raw/eleven_sandstones/BanderaBrown_2d25um_binary.raw'

    savepath = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-07-10]-[test-architectures-large-attn]')
    
    mean_learning_rate = 2e-5 if not mp else 2e-5
    convolution_type = 'default' if not mp else 'mp'

    trainerconfig = poregen.trainers.BinaryVoxelTrainerConfig1(
        voxel_paths,
        savepath,
        image_size=64,
        batch_size=16,
        voxel_downscale_factor=2,
        dimension=3,
        training_dataset_size=34560,
        validation_dataset_size=3840,
        num_epochs=30,
        num_lr_cycles=1,
        learning_scheduler=scheduler,
        psplit=0.8,
        center=True,
        warmup_step_percentage=0.05,
        mean_learning_rate=mean_learning_rate
    )

    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=model_channels,
                                              dropout=0.0,
                                              cond_dropout=0.0,
                                              number_resnet_attn_block=2,
                                              number_resnet_before_attn_block=0,
                                              number_resnet_after_attn_block=2,
                                              dimension=3,
                                              convolution_type=convolution_type,
                                              channel_expansion=[2, 4],
                                              affine_norm=False,
                                              bias=False,
                                              attn_residual=True,
                                              in_out_kernel_size=3,
                                              in_embedding=in_embeddings)
    model = poregen.models.PUNetG(modelconfig)
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm(sigma_data=1.0)
    _ = poregen.trainers.train_binary_voxel_1(
        model=model,
        moduleconfig=moduleconfig,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="ddp",
        conditional=False
    )

================
File: training/training-script-20240710-test-different-nets.py
================
import os
import pathlib
import argparse

import poregen.data
import poregen.models
import poregen.trainers
import poregen.features


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-channels', type=int, default=16)
    parser.add_argument('--scheduler', type=str, default='constant')

    parser.add_argument('--in-embedding',
                        default=False,
                        action=argparse.BooleanOptionalAction)
    parser.add_argument('--mp',
                        default=False,
                        action=argparse.BooleanOptionalAction)

    args = parser.parse_args()
    model_channels = args.model_channels
    scheduler = args.scheduler
    in_embeddings = args.in_embedding
    mp = args.mp

    # sandstones = sorted([
        # b for b in os.listdir(MAINPATH/'saveddata/raw/eleven_sandstones')
        # if 'binary' in b])[-3:]

    # voxel_paths = [MAINPATH/'saveddata/raw/eleven_sandstones'/sandstone for 
                #    sandstone in sandstones]
    # voxel_paths = sorted(voxel_paths)[:8]

    voxel_paths = MAINPATH/'saveddata/raw/eleven_sandstones/BanderaBrown_2d25um_binary.raw'

    savepath = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-07-10]-[test-architectures-large-no-attn]')
    
    mean_learning_rate = 2e-5 if not mp else 2e-5
    convolution_type = 'default' if not mp else 'mp'

    trainerconfig = poregen.trainers.BinaryVoxelTrainerConfig1(
        voxel_paths,
        savepath,
        image_size=64,
        batch_size=16,
        voxel_downscale_factor=2,
        dimension=3,
        training_dataset_size=34560,
        validation_dataset_size=3840,
        num_epochs=30,
        num_lr_cycles=1,
        learning_scheduler=scheduler,
        psplit=0.8,
        center=True,
        warmup_step_percentage=0.05,
        mean_learning_rate=mean_learning_rate
    )

    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=model_channels,
                                              dropout=0.0,
                                              cond_dropout=0.0,
                                              number_resnet_attn_block=0,
                                              number_resnet_before_attn_block=2,
                                              number_resnet_after_attn_block=2,
                                              dimension=3,
                                              convolution_type=convolution_type,
                                              channel_expansion=[2, 4],
                                              affine_norm=False,
                                              bias=False,
                                              in_out_kernel_size=3,
                                              in_embedding=in_embeddings)
    model = poregen.models.PUNetG(modelconfig)
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm(sigma_data=1.0)
    _ = poregen.trainers.train_binary_voxel_1(
        model=model,
        moduleconfig=moduleconfig,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="ddp",
        conditional=False
    )

================
File: training/training-script-20240711-karras-ldm3d-a100.py
================
import pathlib
import argparse
import functools

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 voxel_size: int = 32,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 30,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.voxel_size = voxel_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler
    

def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    voxel_size = config.voxel_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=voxel_size)
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=voxel_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=255)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=255)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 1
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))
    dataloader_size = len(train_dataloader)

    torch.set_float32_matmul_precision('medium')

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                strategy="ddp",
                                fast_dev_run=False,
                                gradient_clip_val=0.5)

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--voxelsize', type=int, default=64)
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    # imagesize = args.imagesize
    voxel_size = args.voxelsize

    netconfig = poregen.models.PUNetGConfig(input_channels=4,
                                        output_channels=4,
                                        dimension=3,
                                        number_resnet_attn_block=0,
                                        number_resnet_before_attn_block=3,
                                        number_resnet_after_attn_block=3)
    model = poregen.models.PUNetG(netconfig)
    
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    # moduleconfig.loss_metric = "mse"        # for encoded data

    checkpoint_path=(MAINPATH/'savedmodels/experimental/[pore]-[2024-07-15]-[bps]-[64-autoencoder-1e-4]/sample-epoch=16-val/rec_loss=0.006202.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(kl_weight=1e-4)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        resolution=voxel_size)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    diffcheckpoint = (MAINPATH/'savedmodels/experimental/[pore]-[2024-07-22]-[bps]-[punetg3d-noatt-latent64-att641e-4vae-cont]/sample-epoch=99-valid_loss=1.206650.ckpt')

    module = poregen.models.KarrasModule.load_from_checkpoint(
        diffcheckpoint,
        model=model,
        config=moduleconfig,
        autoencoder=vae_module)

    # module = poregen.models.KarrasModule(
    #     model=model,
    #     config=moduleconfig,
    #     autoencoder=vae_module)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    voxel_size=voxel_size,
                    learning_rate=1e-3,
                    batch_size=8,       # effective batch size: 8x8 = 64
                    num_epochs=100)
    
    main(config, module)

================
File: training/training-script-20240716-karras-ldm3d-256-a100.py
================
import pathlib
import argparse

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 voxel_size: int = 32,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 30,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.voxel_size = voxel_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    voxel_size = config.voxel_size
    batch_size = config.batch_size

    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=voxel_size)
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=voxel_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=64)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=64)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 1
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))
    dataloader_size = len(train_dataloader)

    torch.set_float32_matmul_precision('medium')

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                strategy="ddp",
                                fast_dev_run=False,
                                gradient_clip_val=0.5,
                                accumulate_grad_batches=2)

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--voxelsize', type=int, default=256)
    datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    # kindofdata = 'eleven'
    # savefolderstr = '[pore]-[2024-05-06]-[bps]-[bereapunetb]'
    args = parser.parse_args()
    # datastr = args.datastr
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    # imagesize = args.imagesize
    voxel_size = args.voxelsize

    netconfig = poregen.models.PUNetGConfig(input_channels=4,
                                        output_channels=4,
                                        dimension=3,
                                        number_resnet_attn_block=0,
                                        number_resnet_before_attn_block=3,
                                        number_resnet_after_attn_block=3)
    model = poregen.models.PUNetG(netconfig)
    
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()

    # moduleconfig.loss_metric = "mse"        # for encoded data

    checkpoint_path=(MAINPATH/'savedmodels/experimental/[pore]-[2024-07-08]-[bps]-[128-noatt-autoencoder-1e-6]/sample-epoch=17-val/rec_loss=0.004139.ckpt')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig()
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        resolution=voxel_size,
        has_mid_attn=False)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    # diffcheckpoint = (MAINPATH/'savedmodels/experimental/[pore]-[2024-07-15]-[bps]-[punetg3d-noatt-latent64-att641e-4vae]/sample-epoch=117-valid_loss=1.640460.ckpt')

    # module = poregen.models.KarrasModule.load_from_checkpoint(
    #     diffcheckpoint,
    #     model=model,
    #     config=moduleconfig,
    #     autoencoder=vae_module)

    module = poregen.models.KarrasModule(
        model=model,
        config=moduleconfig,
        autoencoder=vae_module)

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    psplit=0.744,
                    voxel_size=voxel_size,
                    learning_rate=1e-3,
                    batch_size=2,       # effective batch size: 2x2x8 = 32
                    num_epochs=100)
    
    main(config, module)

================
File: training/training-script-20240717-test.py
================
import os
import pathlib
import argparse

import poregen.data
import poregen.models
import poregen.trainers
import poregen.features


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model-channels', type=int, default=16)
    parser.add_argument('--scheduler', type=str, default='constant')
    args = parser.parse_args()
    model_channels = args.model_channels
    scheduler = args.scheduler



    voxel_paths = MAINPATH/'saveddata/raw/eleven_sandstones/BanderaBrown_2d25um_binary.raw'

    savepath = (MAINPATH/
        'savedmodels/experimental/[pore]-[2024-07-16]-[test-config]')
    trainerconfig = poregen.trainers.BinaryVoxelTrainerConfig1(
        voxel_paths,
        savepath,
        image_size=64,
        batch_size=4,
        voxel_downscale_factor=2,
        dimension=2,
        training_dataset_size=34560,
        validation_dataset_size=3840,
        num_epochs=1,
        num_lr_cycles=2,
        learning_scheduler=scheduler,
        psplit=0.8,
        center=True,
        warmup_step_percentage=0.05,
        mean_learning_rate=4*1e-5
    )

    modelconfig = poregen.models.PUNetGConfig(input_channels=1,
                                              output_channels=1,
                                              model_channels=model_channels,
                                              dropout=0.0,
                                              cond_dropout=0.0,
                                              number_resnet_attn_block=2,
                                              number_resnet_before_attn_block=2,
                                              number_resnet_after_attn_block=2,
                                              dimension=2,
                                              convolution_type='default',
                                              channel_expansion=[2, 4, 8])
    model = poregen.models.PUNetG(modelconfig)
    moduleconfig = poregen.models.KarrasModuleConfig.from_edm(sigma_data=0.5)
    _ = poregen.trainers.train_binary_voxel_1(
        model=model,
        moduleconfig=moduleconfig,
        trainerconfig=trainerconfig,
        fast_dev_run=False,
        strategy="auto",
        conditional=False
    )

================
File: training/training-script-20240723-karras-ldm3d-norm-a100.py
================
import pathlib
import argparse
import functools

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.features
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 accum_batch: int = 1,
                 num_workers: int = 255,
                 devices: int = 8,
                 continuation: bool = False,
                 condition: None | str = None,
                 voxel_size: int = 32,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 30,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.accum_batch = accum_batch
        self.num_workers = num_workers
        self.devices = devices
        self.continuation = continuation
        self.condition = condition
        self.voxel_size = voxel_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler
    

def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    voxel_size = config.voxel_size
    batch_size = config.batch_size
    condition = config.condition
    
    if condition=='porosity':
        extract_condition = poregen.features.feature_extractors.extract_porosity
    elif condition=='tpc':
        extract_condition = poregen.features.feature_extractors.extract_two_point_correlation_from_voxel
    elif condition=='psd':
        extract_condition = poregen.features.feature_extractors.extract_porosimetry_from_voxel
    else:
        extract_condition = None
    
    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=voxel_size,
        feature_extractor=extract_condition)
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=voxel_size,
        feature_extractor=extract_condition)

    num_workers = config.num_workers
    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 1
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))
    dataloader_size = len(train_dataloader)

    torch.set_float32_matmul_precision('medium')

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                strategy="ddp",
                                devices=config.devices,
                                accumulate_grad_batches=config.accum_batch,
                                fast_dev_run=False,
                                gradient_clip_val=0.5)

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--model', type=str, default='punetg')
    parser.add_argument('--loss', type=str, default='huber')
    parser.add_argument('--batchnorm', type=str, default='no')
    parser.add_argument('--attention', type=str, default='no')
    parser.add_argument('--continuation', type=str, default='no')
    parser.add_argument('--sandstone', type=str, default='berea')
    parser.add_argument('--condition', type=str, default=None)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--voxelsize', type=int, default=64)
    parser.add_argument('--devices', type=int, default=8)
    args = parser.parse_args()

    sandstone = args.sandstone
    if sandstone=='berea':
        datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
        checkpoint_path = (MAINPATH/'savedmodels/production/[pore]-[2024-07-09]-[bps]-[64berea-noatt-autoencoder-1e-4]/sample-epoch=95-val/rec_loss=0.003954.ckpt')
    elif sandstone=='banderabrown':
        datastr = 'eleven_sandstones/BanderaBrown_2d25um_binary.raw'
        checkpoint_path = (MAINPATH/'savedmodels/production/[pore]-[2024-08-13]-[bps]-[64banderabrown-noatt-autoencoder-1e-4]/sample-epoch=104-val/rec_loss=0.005341.ckpt')
    elif sandstone=='estaillades':
        datastr = 'imperial_college/Estaillades_1000c_3p31136um.raw'
        checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-09-10]-[bps]-[64estaillades-noatt-autoencoder-1e-4]/sample-epoch=31-val/rec_loss=0.002858.ckpt')
    else:
        raise ValueError('-sandstone argument should be either berea, banderabrown or estaillades')
    
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    net = args.model
    voxel_size = args.voxelsize
    devices = args.devices
    condition = args.condition
    print('Condition: ', condition)

    if args.continuation=='yes':
        continuation=True
    elif args.continuation=='no':
        continuation=False
    else:
        raise ValueError('--continuation argument should be either yes or no')
    
    if args.batchnorm=='yes':
        batchnorm=True
    elif args.batchnorm=='no':
        batchnorm=False
    else:
        raise ValueError('--batchnorm argument should be either yes or no')
    
    if args.attention=='yes':
        attention=True
    elif args.attention=='no':
        attention=False
    else:
        raise ValueError('--attention argument should be either yes or no')
    
    psplit = 0.8
    batch_size = 4
    accum_batch = 1
    num_workers = 255
    dropout = 0
    
    if voxel_size==256:
        psplit = 0.7
        num_workers = 1
        batch_size = 1
        accum_batch = 4
        num_workers = 32
        dropout = 0.1
    
    if condition=='tpc' or condition=='psd':
        num_workers=100

    if net=='punetg':
        model_channels=64
        if attention:
            netconfig = poregen.models.PUNetGConfig(
                input_channels=4,
                output_channels=4,
                dimension=3,
                model_channels=model_channels,
                dropout=dropout)
        else:
            netconfig = poregen.models.PUNetGConfig(
                input_channels=4,
                output_channels=4,
                model_channels=model_channels,
                dimension=3,
                number_resnet_attn_block=0,
                number_resnet_before_attn_block=3,
                number_resnet_after_attn_block=3,
                dropout=dropout)

        if condition is not None:
            if condition=='porosity':
                embedder = poregen.models.PorosityEmbedder(model_channels)
            elif condition=='tpc':
                pre_embedder = poregen.models.TwoPointCorrelationEmbedder(model_channels)
                embedder = poregen.models.TwoPointCorrelationTransformer(
                    pre_embedder
                )
            elif condition=='psd':
                pre_embedder = poregen.models.PoreSizeDistEmbedder(model_channels)
                embedder = poregen.models.PoreSizeDistTransformer(
                    pre_embedder
                )
            else:
                raise NameError('Condition unrecognized')
            
            model = poregen.models.PUNetG(netconfig, embedder)
        else:
            model = poregen.models.PUNetG(netconfig)

    elif net=='edm2':
        model = poregen.models.UNet3D(img_resolution=voxel_size,
                                      img_channels=4,
                                      label_dim=0,
                                      model_channels=64,
                                      channel_mult=[1,2,3],     # avoid unidimensional embeddings for the voxel
                                      dropout=0.1)
    else:
        raise NameError('argument --model should be either edm2 or punetg')
    
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    
    moduleconfig.loss_metric = args.loss
    print('Using ', moduleconfig.loss_metric, ' loss.')

    if batchnorm:
        moduleconfig.has_edm_batch_norm=True


    # if voxel_size==64:
    #     if sandstone=='berea':
    #         checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-07-09]-[bps]-[64-noatt-autoencoder-1e-4]/sample-epoch=95-val/rec_loss=0.003954.ckpt')
    #     elif sandstone=='banderabrown':
    #         checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-08-13]-[bps]-[64-noatt-autoencoder-1e-4-banderabrown]/sample-epoch=104-val/rec_loss=0.005341.ckpt')
        
    #     checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-07-09]-[bps]-[64-noatt-autoencoder-1e-4]/sample-epoch=95-val/rec_loss=0.003954.ckpt')
    #     # testing something
    # elif voxel_size==128:
    #     # Trying something
    #     checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-07-09]-[bps]-[64-noatt-autoencoder-1e-4]/sample-epoch=95-val/rec_loss=0.003954.ckpt')
    # else:
    #     raise ValueError('Please train autoencoder on ', voxel_size, '-sized voxels.')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(kl_weight=1e-4)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        resolution=voxel_size,
        has_mid_attn=False)

    vae_module = poregen.models.nets.autoencoderldm3d.AutoencoderKL.load_from_checkpoint(
        checkpoint_path, ddconfig=ddconfig, lossconfig=lossconfig
        )
    vae_module.eval()

    conditional = True if condition is not None else False

    if continuation:
        diffcheckpoint = (MAINPATH/'savedmodels/experimental/[pore]-[2024-08-05]-[bps]-[punetg-latent64-noatt4vae-batchnorm-mse]/sample-epoch=113-valid_loss=0.762119.ckpt')
        module = poregen.models.KarrasModule.load_from_checkpoint(
            diffcheckpoint,
            model=model,
            config=moduleconfig,
            conditional=conditional,
            autoencoder=vae_module)
    else:
        module = poregen.models.KarrasModule(
            model=model,
            config=moduleconfig,
            conditional=conditional,
            autoencoder=vae_module)
    
    # # get latent space between -0.5 and 0.5
    if not batchnorm:
        module.norm = 20
    else:
        module.norm = 4
    

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    voxel_size=voxel_size,
                    psplit=psplit,
                    accum_batch=accum_batch,
                    num_workers=num_workers,
                    devices=devices,
                    continuation=continuation,
                    condition=condition,
                    learning_rate=2e-3,
                    batch_size=batch_size,       # effective batch size: bs x accumulate batches x 8
                    num_epochs=50)
    
    main(config, module)

================
File: training/training-script-20240821-autoencoder_ldm3d-a100-refactor.py
================
import pathlib
import argparse

import torch
# import numpy as np
import lightning
from lightning.pytorch.tuner.tuning import Tuner
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models

torch.cuda.empty_cache()

CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 64,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    # image_size = config.image_size
    batch_size = config.batch_size
    image_size = config.image_size

    transform = poregen.data.get_standard_binary_transforms()

    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=image_size)
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=255)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False, num_workers=255)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='val/rec_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{val/rec_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                strategy="ddp",
                                fast_dev_run=False,
                                gradient_clip_val=0.5)

    # tuner = Tuner(trainer)
    module.learning_rate = config.learning_rate
    # tuner.lr_find(module)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)

    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 5
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))

    torch.set_float32_matmul_precision('medium')

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


# class TemporaryModel(poregen.models.nets.MLPUncond):
#     def forward(self, x, t):
#         oldshape = list(x.shape)
#         newshape = np.prod(oldshape[1:])
#         x = super().forward(x.reshape(-1, newshape), t)
#         x = x.reshape(*oldshape)
#         return x


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # parser.add_argument('--datastr', type=str, required=True)
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--image-size', type=int, default=64)
    parser.add_argument('--sandstone', type=str, default='berea')
    args = parser.parse_args()
    kindofdata = args.kindofdata
    # savefolderstr = '[pore]-[2024-05-14]-[bps]-[ldmvae3d]'
    savefolderstr = args.savefolderstr
    imagesize = args.image_size

    sandstone = args.sandstone
    if sandstone=='berea':
        datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
    elif sandstone=='banderabrown':
        datastr = 'eleven_sandstones/BanderaBrown_2d25um_binary.raw'
    else:
        raise ValueError('-sandstone argument should be either berea or banderabrown')

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(kl_weight=1e-4)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        resolution=imagesize,
        has_mid_attn=False,
        ch_mult=[1, 2, 4, 4, 4],
        z_channels=8)

    vae_model = poregen.models.nets.autoencoderldm3d.AutoencoderKL(ddconfig,
                                                                   lossconfig)
    # checkpoint = (MAINPATH/'savedmodels/experimental' /
    #               '[pore]-[2024-05-14]-[bps]-[ldmvae3d]' /
    #               'sample-epoch=09-val/rec_loss=0.020127.ckpt')

    # vae_model = (
    #     poregen.models.nets.autoencoderldm3d.AutoencoderKL
    #     .load_from_checkpoint(
    #         checkpoint, ddconfig=ddconfig, lossconfig=lossconfig
    #         )
    # )

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3,
                    batch_size=4,       # effective batch size: 8 x 4 = 32
                    num_epochs=150)

    main(config, vae_model)

================
File: training/training-script-20240826-autoencoder_ldm3d-all-a100.py
================
import pathlib
import argparse
import os

import torch
# import numpy as np
import lightning
from lightning.pytorch.tuner.tuning import Tuner
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.models

torch.cuda.empty_cache()

CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 valid_sandstones: tuple,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 image_size: int = 64,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 50,
                 num_workers: int = 100,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.valid_sandstones = valid_sandstones
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.image_size = image_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        self.num_workers = num_workers
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler


def main(config, module):
    valid_sandstones = config.valid_sandstones
    files = [f
             for f in os.listdir(RAWDATAPATH/'eleven_sandstones')
             if f.endswith('binary.raw') and not any(word in f for word in valid_sandstones)]
    print('Files:', files)
    train_voxels = []
    valid_voxels = []
    for file in files:
        voxel = (poregen.
                 data.
                 binary_datasets.
                 load_binary_from_eleven_sandstones(
                     RAWDATAPATH/'eleven_sandstones'/file))
        split = int(voxel.shape[0]*config.psplit)
        train_voxels.append(voxel[:split])
        valid_voxels.append(voxel[split:])
        del voxel

    num_workers = config.num_workers
    batch_size = config.batch_size
    image_size = config.image_size

    transform = poregen.data.get_standard_binary_transforms()
    dataset_cls = (poregen.
                   data.
                   binary_datasets.
                   SequenceOfVoxelsToSubvoxelDataset)

    train_dataset = dataset_cls(
        train_voxels,
        transform=transform,
        subslice=image_size)
    val_dataset = dataset_cls(
        valid_voxels,
        transform=transform,
        subslice=image_size)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='val/rec_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{val/rec_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                strategy="ddp",
                                fast_dev_run=False,
                                gradient_clip_val=0.5)

    # tuner = Tuner(trainer)
    module.learning_rate = config.learning_rate
    # tuner.lr_find(module)

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)

    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 5
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))

    torch.set_float32_matmul_precision('medium')

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--imagesize', type=int, default=64)
    parser.add_argument('--validsandstones', type=tuple, default=('Berea','BanderaBrown'))
    args = parser.parse_args()
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    imagesize = args.imagesize

    valid_sandstones = args.validsandstones

    lossconfig = poregen.models.nets.autoencoderldm3d.lossconfig(kl_weight=1e-4)
    ddconfig = poregen.models.nets.autoencoderldm3d.ddconfig(
        resolution=imagesize,
        has_mid_attn=False)

    vae_model = poregen.models.nets.autoencoderldm3d.AutoencoderKL(ddconfig,
                                                                   lossconfig)
    # checkpoint = (MAINPATH/'savedmodels/experimental' /
    #               '[pore]-[2024-05-14]-[bps]-[ldmvae3d]' /
    #               'sample-epoch=09-val/rec_loss=0.020127.ckpt')

    # vae_model = (
    #     poregen.models.nets.autoencoderldm3d.AutoencoderKL
    #     .load_from_checkpoint(
    #         checkpoint, ddconfig=ddconfig, lossconfig=lossconfig
    #         )
    # )

    config = Config(valid_sandstones,
                    kindofdata,
                    savefolderstr,
                    image_size=imagesize,
                    lr_scheduler='cosine',
                    learning_rate=1e-3,
                    batch_size=4,       # effective batch size: 8 x 4 = 32
                    num_epochs=150)

    main(config, vae_model)

================
File: training/training-script-20240916-karras-nolatent-norm-a100.py
================
import pathlib
import argparse
import functools

import torch
import lightning
import lightning.pytorch.callbacks as callbacks
import transformers

import poregen.data
import poregen.features
import poregen.models


CURRENTPATH = pathlib.Path(__file__).parent.absolute()
MAINPATH = CURRENTPATH.parent.parent
DATAPATH = MAINPATH/"saveddata"  # This leads to the data folder
RAWDATAPATH = DATAPATH/"raw"  # This leads to the data folder
MODELSPATH = MAINPATH/"savedmodels"/"experimental"


class Config:
    def __init__(self,
                 datastr: str,
                 kindofdata: str,
                 savefolderstr: str,
                 psplit: float = 0.8,
                 batch_size: int = 16,
                 accum_batch: int = 1,
                 num_workers: int = 255,
                 devices: int = 8,
                 continuation: bool = False,
                 condition: None | str = None,
                 voxel_size: int = 32,
                 learning_rate: float = 2*1e-5,
                 num_epochs: int = 30,
                 lr_scheduler: None | str = None):
        assert kindofdata in ['eleven', 'porespy']
        self.datastr = datastr
        self.kindofdata = kindofdata
        self.savefolderstr = savefolderstr
        self.psplit = psplit
        self.batch_size = batch_size
        self.accum_batch = accum_batch
        self.num_workers = num_workers
        self.devices = devices
        self.continuation = continuation
        self.condition = condition
        self.voxel_size = voxel_size
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        if lr_scheduler is not None:
            assert lr_scheduler in ['cosine', 'constant']
        self.lr_scheduler = lr_scheduler
    

def main(config, module):
    path = RAWDATAPATH/config.datastr
    if config.kindofdata == 'eleven':
        voxel = poregen.data.load_binary_from_eleven_sandstones(path)
    elif config.kindofdata == 'porespy':
        voxel = poregen.data.load_porespy_generated(path)
    else:
        raise ValueError('Invalid kind of data.')
    split = int(voxel.shape[0]*config.psplit)
    voxel = voxel - 0.5
    train_voxel = voxel[:split, :, :]  # Separate in train voxel
    valid_voxel = voxel[split:, :, :]  # Separate in validation voxel
    del voxel

    transform = poregen.data.get_standard_binary_transforms()
    voxel_size = config.voxel_size
    batch_size = config.batch_size
    condition = config.condition
    
    if condition=='porosity':
        extract_condition = poregen.features.feature_extractors.extract_porosity
    elif condition=='tpc':
        extract_condition = poregen.features.feature_extractors.extract_two_point_correlation_from_voxel
    elif condition=='psd':
        extract_condition = poregen.features.feature_extractors.extract_porosimetry_from_voxel
    else:
        extract_condition = None
    
    train_dataset = poregen.data.VoxelToSubvoxelDataset(
        train_voxel,
        transform=transform,
        subslice=voxel_size,
        feature_extractor=extract_condition)
    val_dataset = poregen.data.VoxelToSubvoxelDataset(
        valid_voxel,
        transform=transform,
        subslice=voxel_size,
        feature_extractor=extract_condition)

    num_workers = config.num_workers
    train_dataloader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers)
    val_dataloader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers)

    checkpoint_callback = callbacks.ModelCheckpoint(
        monitor='valid_loss',
        dirpath=MODELSPATH/config.savefolderstr,
        filename='sample-{epoch:02d}-{valid_loss:.6f}',
        save_top_k=3,
        mode='min',
    )

    module.optimizer = torch.optim.AdamW(module.parameters(),
                                         lr=config.learning_rate)
    dataloader_size = len(train_dataloader)
    num_warmup_steps = 5*dataloader_size
    num_cycles = 1
    num_training_steps = len(train_dataloader)*config.num_epochs
    module.lr_scheduler = (
        transformers.get_cosine_with_hard_restarts_schedule_with_warmup(
            optimizer=module.optimizer,
            num_warmup_steps=num_warmup_steps,
            num_training_steps=num_training_steps,
            num_cycles=num_cycles
        ))
    dataloader_size = len(train_dataloader)

    torch.set_float32_matmul_precision('medium')

    trainer = lightning.Trainer(max_epochs=config.num_epochs,
                                callbacks=[checkpoint_callback],
                                accelerator="gpu",
                                strategy="ddp",
                                devices=config.devices,
                                accumulate_grad_batches=config.accum_batch,
                                fast_dev_run=False,
                                gradient_clip_val=0.5)

    trainer.fit(model=module,
                train_dataloaders=train_dataloader,
                val_dataloaders=val_dataloader)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--kindofdata', type=str,
                        choices=['eleven', 'porespy'],
                        default='eleven')
    parser.add_argument('--savefolderstr', type=str, required=True)
    parser.add_argument('--model', type=str, default='punetg')
    parser.add_argument('--loss', type=str, default='huber')
    parser.add_argument('--batchnorm', type=str, default='no')
    parser.add_argument('--attention', type=str, default='no')
    parser.add_argument('--continuation', type=str, default='no')
    parser.add_argument('--sandstone', type=str, default='berea')
    parser.add_argument('--condition', type=str, default=None)
    parser.add_argument('--channels', type=int, default=64)
    parser.add_argument('--framework', type=str, default='edm',
                        choices=['edm', 'vp'])
    parser.add_argument('--voxelsize', type=int, default=64)
    parser.add_argument('--devices', type=int, default=8)
    args = parser.parse_args()

    sandstone = args.sandstone
    if sandstone=='berea':
        datastr = 'eleven_sandstones/Berea_2d25um_binary.raw'
        checkpoint_path = (MAINPATH/'savedmodels/production/[pore]-[2024-07-09]-[bps]-[64berea-noatt-autoencoder-1e-4]/sample-epoch=95-val/rec_loss=0.003954.ckpt')
    elif sandstone=='banderabrown':
        datastr = 'eleven_sandstones/BanderaBrown_2d25um_binary.raw'
        checkpoint_path = (MAINPATH/'savedmodels/production/[pore]-[2024-08-13]-[bps]-[64banderabrown-noatt-autoencoder-1e-4]/sample-epoch=104-val/rec_loss=0.005341.ckpt')
    elif sandstone=='estaillades':
        datastr = 'imperial_college/Estaillades_1000c_3p31136um.raw'
        checkpoint_path = (MAINPATH/'savedmodels/experimental/[pore]-[2024-09-10]-[bps]-[64estaillades-noatt-autoencoder-1e-4]/sample-epoch=31-val/rec_loss=0.002858.ckpt')
    else:
        raise ValueError('-sandstone argument should be either berea, banderabrown or estaillades')
    
    kindofdata = args.kindofdata
    savefolderstr = args.savefolderstr
    net = args.model
    voxel_size = args.voxelsize
    devices = args.devices
    condition = args.condition
    print('Condition: ', condition)
    model_channels = args.channels

    if args.continuation=='yes':
        continuation=True
    elif args.continuation=='no':
        continuation=False
    else:
        raise ValueError('--continuation argument should be either yes or no')
    
    if args.batchnorm=='yes':
        batchnorm=True
    elif args.batchnorm=='no':
        batchnorm=False
    else:
        raise ValueError('--batchnorm argument should be either yes or no')
    
    if args.attention=='yes':
        attention=True
    elif args.attention=='no':
        attention=False
    else:
        raise ValueError('--attention argument should be either yes or no')
    
    psplit = 0.8
    batch_size = 4
    accum_batch = 1
    num_workers = 255
    dropout = 0.1    

    if net=='punetg':
        if attention:
            netconfig = poregen.models.PUNetGConfig(
                input_channels=1,
                output_channels=1,
                dimension=3,
                model_channels=model_channels,
                dropout=dropout)
        else:
            netconfig = poregen.models.PUNetGConfig(
                input_channels=1,
                output_channels=1,
                model_channels=model_channels,
                dimension=3,
                number_resnet_attn_block=0,
                number_resnet_before_attn_block=3,
                number_resnet_after_attn_block=3,
                dropout=dropout)

        if condition is not None:
            if condition=='porosity':
                embedder = poregen.models.PorosityEmbedder(model_channels)
            elif condition=='tpc':
                pre_embedder = poregen.models.TwoPointCorrelationEmbedder(model_channels)
                embedder = poregen.models.TwoPointCorrelationTransformer(
                    pre_embedder
                )
            elif condition=='psd':
                pre_embedder = poregen.models.PoreSizeDistEmbedder(model_channels)
                embedder = poregen.models.PoreSizeDistTransformer(
                    pre_embedder
                )
            else:
                raise NameError('Condition unrecognized')
            
            model = poregen.models.PUNetG(netconfig, embedder)
        else:
            model = poregen.models.PUNetG(netconfig)

    elif net=='edm2':
        model = poregen.models.UNet3D(img_resolution=voxel_size,
                                      img_channels=1,
                                      label_dim=0,
                                      model_channels=model_channels,
                                      channel_mult=[1,2,3],     # avoid unidimensional embeddings for the voxel
                                      dropout=0.1)
    else:
        raise NameError('argument --model should be either edm2 or punetg')
    
    if args.framework == 'edm':
        moduleconfig = poregen.models.KarrasModuleConfig.from_edm()
    elif args.framework == 'vp':
        moduleconfig = poregen.models.KarrasModuleConfig.from_vp()
    
    moduleconfig.loss_metric = args.loss
    print('Using ', moduleconfig.loss_metric, ' loss.')

    if batchnorm:
        moduleconfig.has_edm_batch_norm=True

    conditional = True if condition is not None else False

    if continuation:
        diffcheckpoint = (MAINPATH/'savedmodels/experimental/[pore]-[2024-08-05]-[bps]-[punetg-latent64-noatt4vae-batchnorm-mse]/sample-epoch=113-valid_loss=0.762119.ckpt')
        module = poregen.models.KarrasModule.load_from_checkpoint(
            diffcheckpoint,
            model=model,
            config=moduleconfig,
            conditional=conditional)
    else:
        module = poregen.models.KarrasModule(
            model=model,
            config=moduleconfig,
            conditional=conditional)
    
    

    config = Config(datastr,
                    kindofdata,
                    savefolderstr,
                    voxel_size=voxel_size,
                    psplit=psplit,
                    accum_batch=accum_batch,
                    num_workers=num_workers,
                    devices=devices,
                    continuation=continuation,
                    condition=condition,
                    learning_rate=1.25e-4,
                    batch_size=batch_size,       # effective batch size = bs x accumulate batches x devices
                    num_epochs=35)
    
    main(config, module)

================
File: 20231211-test-run.py
================
import pathlib
import argparse

import torch
import numpy as np
import einops
import poregen.models


MAINFOLDER = pathlib.Path(".")
RAWDATAFOLDER = MAINFOLDER/"saveddata"/"raw"/"gravity_packing"


class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, scale_factor=4):
        self.dataset = dataset

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        x = self.dataset[idx].unsqueeze(0)
        return x


def extract_subvolumes(voxel, width=128, height=128, depth=16, stride=32):
    # Precomputing the number of steps along each dimension
    steps_x = (voxel.shape[0] - width) // stride + 1
    steps_y = (voxel.shape[1] - height) // stride + 1
    steps_z = (voxel.shape[2] - depth) // stride + 1

    # Initializing an empty list to hold the sub-volumes
    subvolumes = []

    # Nested loops to traverse the voxel and extract sub-volumes
    for i in range(steps_x):
        for j in range(steps_y):
            for k in range(steps_z):
                # Computing the indices for the sub-volume
                x_start, x_end = i * stride, i * stride + width
                y_start, y_end = j * stride, j * stride + height
                z_start, z_end = k * stride, k * stride + depth

                # Extracting and appending the sub-volume to the list
                subvolume = voxel[x_start:x_end, y_start:y_end, z_start:z_end]
                subvolumes.append(subvolume)

    # Converting the list of sub-volumes to a 4D numpy array
    result = np.stack(subvolumes, axis=0)

    return result


def main(nepochs, batch_size, window_size):
    name = "voxel_gravity_packing_p480_r10_n25000_extended_001.npy"
    voxel = np.load(RAWDATAFOLDER/name)
    result = extract_subvolumes(voxel,
                                window_size,
                                window_size,
                                16,
                                stride=16)
    result = einops.rearrange(result, "b x y z -> (b z) x y")
    dataset = CustomDataset(torch.tensor(result, dtype=torch.float))

    batch_size = batch_size
    train_size = int(0.8 * len(dataset))
    test_size = len(dataset) - train_size
    train_dataset, test_dataset = torch.utils.data.random_split(dataset,
                                                                [train_size,
                                                                 test_size])

    train_dataloader = torch.utils.data.DataLoader(train_dataset,
                                                   batch_size=batch_size,
                                                   shuffle=True,
                                                   num_workers=4)
    test_dataloader = torch.utils.data.DataLoader(test_dataset,
                                                  batch_size=batch_size,
                                                  shuffle=True,
                                                  num_workers=4)

    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    model = poregen.models.HFNetUncond([16, 32, 64], norm_num_groups=8)
    model = model.to(device)
    scheduler = poregen.models.DDPMScheduler()
    trainer = poregen.models.UncondDDPMTrainer(model, scheduler,
                                               train_dataloader,
                                               test_dataloader=test_dataloader,
                                               device=device,
                                               loss_scale_factor=100.0)
    trainer.set_optimizer_and_scheduler()
    trainer.train(nepochs=100)
    trainer.save_model("savedmodels/121109_testscript.pth")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Process some integers.')
    parser.add_argument('--nepochs', type=int, default=100,
                        help='Number of epochs (default: 100)')
    parser.add_argument('--length', type=int, default=32,
                        help='Length of window (default: 32)')
    parser.add_argument('--batch-size', type=int, default=64,
                        help='Batch size (default: 64)')

    # Parse arguments
    args = parser.parse_args()
    main(args.nepochs, args.batch_size, args.length)

================
File: clean_ipynb.sh
================
#!/bin/bash

# Fetch all branches
git fetch --all

# List all remote branches
branches=$(git branch -r | grep -v '\->')

# Loop through each branch
for branch in $branches; do
    # Checkout the branch
    branch_name=${branch#origin/}
    git checkout $branch_name

    # Remove .ipynb files in the specified directory
    find notebooks/exploratory -name '*.ipynb' -not -name 'GITSHARE*.ipynb' -exec git rm --cached {} \;

    # Commit the changes
    git commit -m "Remove .ipynb files from notebooks/exploratory/ directory"

    # Push the changes to the remote repository
    git push origin $branch_name
done

# Clean up local branches
git checkout main

# Use filter-branch to remove .ipynb files from history in the specified directory
git filter-branch --force --index-filter \
  'git rm -r --cached --ignore-unmatch notebooks/exploratory/*.ipynb' \
  --prune-empty --tag-name-filter cat -- --all

# Force push the changes to the remote repository
git push --force --all
git push --force --tags

# Instruct collaborators to clean up their local repositories
echo "Inform collaborators to run the following commands:
# Fetch all branches
git fetch --all

# Checkout each branch and reset it
for branch in \$(git branch -r | grep -v '\->'); do
    branch_name=\${branch#origin/}
    git checkout \$branch_name
    git reset --hard origin/\$branch_name
done

# Clean up local repository
git reflog expire --expire=now --all && git gc --prune=now --aggressive
"

================
File: Dockerfile-20231211-test-run
================
FROM poregen-docker-base

# Copy the new script
COPY scripts/20231211-test-run.py /scripts/20231211-test-run.py

# Command to run the new script
ENTRYPOINT ["python", "/scripts/20231211-test-run.py"]

================
File: models_to_onnx.py
================
# this script transforms all the models in savedmodels/models.json into
# deliverable onnx files. All the models must have an assigned values to the
# attribute self.example_input_array, or else the lightning module method
# to_onnx requires an example of an input sample.

from poregen.models.loader import load_model, list_models


def main():
    config_path = "savedmodels/production"

    model_indentifiers = [
        model_key for model_key in list_models(config_path).keys()
    ]

    for model_indentifier in model_indentifiers:
        model, config_class = load_model(
            config_path=config_path,
            model_identifier=model_indentifier
        )

        filepath = config_path + "/" + model_indentifier[:-4] + "onnx"
        model.to_onnx(filepath, export_params=True)


if __name__ == "__main__":

    main()

================
File: remote_tracking.sh
================
# Fetch all branches
git fetch --all

# Loop through each branch and remove .ipynb files from tracking without deleting them
for branch in $(git branch -r | grep -v '\->'); do
    branch_name=${branch#origin/}
    git checkout $branch_name

    # Remove .ipynb files in the specified directory from tracking without deleting them
    find notebooks/exploratory -name '*.ipynb' -not -name 'GITSHARE*.ipynb' -exec git rm --cached {} \;

    # Commit the changes locally
    git commit -m "Stop tracking .ipynb files in notebooks/exploratory/ directory"

    # Optional: Push the changes if needed
    git push origin $branch_name
done

# Clean up local branches
git checkout main
